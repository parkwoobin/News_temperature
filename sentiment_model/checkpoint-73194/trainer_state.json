{
  "best_metric": 1.0,
  "best_model_checkpoint": "./sentiment_model\\checkpoint-24398",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 73194,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004098696614476596,
      "grad_norm": 3.3053395748138428,
      "learning_rate": 3.920000000000001e-06,
      "loss": 0.8076,
      "step": 100
    },
    {
      "epoch": 0.008197393228953192,
      "grad_norm": 0.8174723982810974,
      "learning_rate": 7.92e-06,
      "loss": 0.1779,
      "step": 200
    },
    {
      "epoch": 0.01229608984342979,
      "grad_norm": 0.25152820348739624,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.0208,
      "step": 300
    },
    {
      "epoch": 0.016394786457906384,
      "grad_norm": 0.07834084331989288,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.0063,
      "step": 400
    },
    {
      "epoch": 0.02049348307238298,
      "grad_norm": 0.03619992733001709,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.0029,
      "step": 500
    },
    {
      "epoch": 0.02459217968685958,
      "grad_norm": 0.021922053769230843,
      "learning_rate": 1.9973037664731617e-05,
      "loss": 0.0014,
      "step": 600
    },
    {
      "epoch": 0.028690876301336175,
      "grad_norm": 0.012903655879199505,
      "learning_rate": 1.994552507772306e-05,
      "loss": 0.0009,
      "step": 700
    },
    {
      "epoch": 0.03278957291581277,
      "grad_norm": 0.017938824370503426,
      "learning_rate": 1.9918012490714505e-05,
      "loss": 0.0006,
      "step": 800
    },
    {
      "epoch": 0.03688826953028937,
      "grad_norm": 0.008281764574348927,
      "learning_rate": 1.9890499903705946e-05,
      "loss": 0.0004,
      "step": 900
    },
    {
      "epoch": 0.04098696614476596,
      "grad_norm": 0.007488916162401438,
      "learning_rate": 1.986298731669739e-05,
      "loss": 0.0003,
      "step": 1000
    },
    {
      "epoch": 0.04508566275924256,
      "grad_norm": 0.006379257421940565,
      "learning_rate": 1.9835474729688834e-05,
      "loss": 0.0003,
      "step": 1100
    },
    {
      "epoch": 0.04918435937371916,
      "grad_norm": 0.004402001854032278,
      "learning_rate": 1.9807962142680278e-05,
      "loss": 0.0002,
      "step": 1200
    },
    {
      "epoch": 0.05328305598819576,
      "grad_norm": 0.00403679208829999,
      "learning_rate": 1.978044955567172e-05,
      "loss": 0.0002,
      "step": 1300
    },
    {
      "epoch": 0.05738175260267235,
      "grad_norm": 0.0035295395646244287,
      "learning_rate": 1.9752936968663165e-05,
      "loss": 0.0001,
      "step": 1400
    },
    {
      "epoch": 0.061480449217148944,
      "grad_norm": 0.0030825238209217787,
      "learning_rate": 1.9725424381654606e-05,
      "loss": 0.0001,
      "step": 1500
    },
    {
      "epoch": 0.06557914583162554,
      "grad_norm": 0.0026788273826241493,
      "learning_rate": 1.9697911794646053e-05,
      "loss": 0.0001,
      "step": 1600
    },
    {
      "epoch": 0.06967784244610215,
      "grad_norm": 0.0022983059752732515,
      "learning_rate": 1.9670399207637497e-05,
      "loss": 0.0001,
      "step": 1700
    },
    {
      "epoch": 0.07377653906057874,
      "grad_norm": 0.002381541533395648,
      "learning_rate": 1.964288662062894e-05,
      "loss": 0.0001,
      "step": 1800
    },
    {
      "epoch": 0.07787523567505533,
      "grad_norm": 0.0015336422948166728,
      "learning_rate": 1.9615374033620382e-05,
      "loss": 0.0001,
      "step": 1900
    },
    {
      "epoch": 0.08197393228953193,
      "grad_norm": 0.0013345403131097555,
      "learning_rate": 1.9587861446611826e-05,
      "loss": 0.0001,
      "step": 2000
    },
    {
      "epoch": 0.08607262890400852,
      "grad_norm": 0.001736747450195253,
      "learning_rate": 1.956034885960327e-05,
      "loss": 0.0001,
      "step": 2100
    },
    {
      "epoch": 0.09017132551848513,
      "grad_norm": 0.00116865208838135,
      "learning_rate": 1.9532836272594714e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.09427002213296172,
      "grad_norm": 0.0009452670346945524,
      "learning_rate": 1.9505323685586157e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.09836871874743831,
      "grad_norm": 0.0008555471431463957,
      "learning_rate": 1.94778110985776e-05,
      "loss": 0.0001,
      "step": 2400
    },
    {
      "epoch": 0.10246741536191491,
      "grad_norm": 0.0007275500101968646,
      "learning_rate": 1.9450298511569042e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 0.10656611197639151,
      "grad_norm": 0.001139226951636374,
      "learning_rate": 1.942278592456049e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 0.11066480859086811,
      "grad_norm": 0.0007873674621805549,
      "learning_rate": 1.9395273337551933e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 0.1147635052053447,
      "grad_norm": 0.0007268556510098279,
      "learning_rate": 1.9367760750543377e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 0.1188622018198213,
      "grad_norm": 0.0005949496407993138,
      "learning_rate": 1.9340248163534818e-05,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 0.12296089843429789,
      "grad_norm": 0.0006955318385735154,
      "learning_rate": 1.931273557652626e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.12705959504877448,
      "grad_norm": 0.000573011115193367,
      "learning_rate": 1.9285222989517706e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.13115829166325108,
      "grad_norm": 0.0004752870590891689,
      "learning_rate": 1.925771040250915e-05,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.13525698827772767,
      "grad_norm": 0.0004112142778467387,
      "learning_rate": 1.9230197815500593e-05,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 0.1393556848922043,
      "grad_norm": 0.0006127802189439535,
      "learning_rate": 1.9202685228492037e-05,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 0.14345438150668088,
      "grad_norm": 0.0005448517622426152,
      "learning_rate": 1.9175172641483478e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 0.14755307812115748,
      "grad_norm": 0.000384710292564705,
      "learning_rate": 1.9147660054474925e-05,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 0.15165177473563407,
      "grad_norm": 0.0003474033437669277,
      "learning_rate": 1.912014746746637e-05,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 0.15575047135011066,
      "grad_norm": 0.00031349892378784716,
      "learning_rate": 1.9092634880457813e-05,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 0.15984916796458726,
      "grad_norm": 0.0002755983150564134,
      "learning_rate": 1.9065122293449254e-05,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 0.16394786457906385,
      "grad_norm": 0.00023273656552191824,
      "learning_rate": 1.9037609706440698e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 0.16804656119354044,
      "grad_norm": 0.0002540042332839221,
      "learning_rate": 1.901009711943214e-05,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 0.17214525780801704,
      "grad_norm": 0.0002646498614922166,
      "learning_rate": 1.8982584532423585e-05,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 0.17624395442249366,
      "grad_norm": 0.00017728024977259338,
      "learning_rate": 1.895507194541503e-05,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 0.18034265103697025,
      "grad_norm": 0.0002536566462367773,
      "learning_rate": 1.8927559358406473e-05,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 0.18444134765144685,
      "grad_norm": 0.00019486194651108235,
      "learning_rate": 1.8900046771397914e-05,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 0.18854004426592344,
      "grad_norm": 0.0001829143729992211,
      "learning_rate": 1.8872534184389358e-05,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 0.19263874088040003,
      "grad_norm": 0.0002424965932732448,
      "learning_rate": 1.8845021597380805e-05,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 0.19673743749487663,
      "grad_norm": 0.0001783435291144997,
      "learning_rate": 1.8817509010372246e-05,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 0.20083613410935322,
      "grad_norm": 0.00024695033789612353,
      "learning_rate": 1.878999642336369e-05,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 0.20493483072382981,
      "grad_norm": 0.0001460575731471181,
      "learning_rate": 1.8762483836355134e-05,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 0.2090335273383064,
      "grad_norm": 0.00015830667689442635,
      "learning_rate": 1.8734971249346577e-05,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 0.21313222395278303,
      "grad_norm": 0.00010220998956356198,
      "learning_rate": 1.870745866233802e-05,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 0.21723092056725962,
      "grad_norm": 0.00011946344602620229,
      "learning_rate": 1.8679946075329465e-05,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 0.22132961718173622,
      "grad_norm": 0.00010346135968575254,
      "learning_rate": 1.865243348832091e-05,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 0.2254283137962128,
      "grad_norm": 0.00011718095629476011,
      "learning_rate": 1.862492090131235e-05,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 0.2295270104106894,
      "grad_norm": 7.75892985984683e-05,
      "learning_rate": 1.8597408314303794e-05,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 0.233625707025166,
      "grad_norm": 9.687766578281298e-05,
      "learning_rate": 1.856989572729524e-05,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 0.2377244036396426,
      "grad_norm": 7.569968147436157e-05,
      "learning_rate": 1.854238314028668e-05,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 0.24182310025411918,
      "grad_norm": 8.544680895283818e-05,
      "learning_rate": 1.8514870553278126e-05,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 0.24592179686859578,
      "grad_norm": 9.643563680583611e-05,
      "learning_rate": 1.848735796626957e-05,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 0.25002049348307237,
      "grad_norm": 7.16063950676471e-05,
      "learning_rate": 1.8459845379261013e-05,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 0.25411919009754896,
      "grad_norm": 8.437517681159079e-05,
      "learning_rate": 1.8432332792252457e-05,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 0.25821788671202556,
      "grad_norm": 7.08104926161468e-05,
      "learning_rate": 1.84048202052439e-05,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 0.26231658332650215,
      "grad_norm": 6.32840019534342e-05,
      "learning_rate": 1.8377307618235345e-05,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 0.26641527994097874,
      "grad_norm": 4.5870303438277915e-05,
      "learning_rate": 1.8349795031226786e-05,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 0.27051397655545534,
      "grad_norm": 8.398201316595078e-05,
      "learning_rate": 1.832228244421823e-05,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 0.274612673169932,
      "grad_norm": 5.979555135127157e-05,
      "learning_rate": 1.8294769857209677e-05,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 0.2787113697844086,
      "grad_norm": 7.460414781235158e-05,
      "learning_rate": 1.8267257270201118e-05,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 0.2828100663988852,
      "grad_norm": 4.138198710279539e-05,
      "learning_rate": 1.823974468319256e-05,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 0.28690876301336177,
      "grad_norm": 3.706945062731393e-05,
      "learning_rate": 1.8212232096184005e-05,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 0.29100745962783836,
      "grad_norm": 4.1110764868790284e-05,
      "learning_rate": 1.818471950917545e-05,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 0.29510615624231495,
      "grad_norm": 5.958510882919654e-05,
      "learning_rate": 1.8157206922166893e-05,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 0.29920485285679155,
      "grad_norm": 5.518131729331799e-05,
      "learning_rate": 1.8129694335158337e-05,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 0.30330354947126814,
      "grad_norm": 3.4870445233536884e-05,
      "learning_rate": 1.810218174814978e-05,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 0.30740224608574473,
      "grad_norm": 5.4137457482283935e-05,
      "learning_rate": 1.8074669161141222e-05,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 0.31150094270022133,
      "grad_norm": 2.3941698600538075e-05,
      "learning_rate": 1.8047156574132666e-05,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 0.3155996393146979,
      "grad_norm": 3.5592413041740656e-05,
      "learning_rate": 1.8019643987124113e-05,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 0.3196983359291745,
      "grad_norm": 3.041671880055219e-05,
      "learning_rate": 1.7992131400115554e-05,
      "loss": 0.0,
      "step": 7800
    },
    {
      "epoch": 0.3237970325436511,
      "grad_norm": 2.8206948627484962e-05,
      "learning_rate": 1.7964618813106997e-05,
      "loss": 0.0,
      "step": 7900
    },
    {
      "epoch": 0.3278957291581277,
      "grad_norm": 2.167154525523074e-05,
      "learning_rate": 1.793710622609844e-05,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 0.3319944257726043,
      "grad_norm": 2.9572325729532167e-05,
      "learning_rate": 1.7909593639089885e-05,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 0.3360931223870809,
      "grad_norm": 2.5298371838289313e-05,
      "learning_rate": 1.788208105208133e-05,
      "loss": 0.0,
      "step": 8200
    },
    {
      "epoch": 0.3401918190015575,
      "grad_norm": 1.916810651891865e-05,
      "learning_rate": 1.7854568465072773e-05,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 0.3442905156160341,
      "grad_norm": 1.4971836208133027e-05,
      "learning_rate": 1.7827055878064217e-05,
      "loss": 0.0,
      "step": 8400
    },
    {
      "epoch": 0.3483892122305107,
      "grad_norm": 1.6786485502962023e-05,
      "learning_rate": 1.7799543291055658e-05,
      "loss": 0.0,
      "step": 8500
    },
    {
      "epoch": 0.3524879088449873,
      "grad_norm": 1.943706229212694e-05,
      "learning_rate": 1.77720307040471e-05,
      "loss": 0.0,
      "step": 8600
    },
    {
      "epoch": 0.3565866054594639,
      "grad_norm": 2.026719448622316e-05,
      "learning_rate": 1.7744518117038546e-05,
      "loss": 0.0,
      "step": 8700
    },
    {
      "epoch": 0.3606853020739405,
      "grad_norm": 1.577649345563259e-05,
      "learning_rate": 1.771700553002999e-05,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 0.3647839986884171,
      "grad_norm": 1.0831557119672652e-05,
      "learning_rate": 1.7689492943021433e-05,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 0.3688826953028937,
      "grad_norm": 1.0929237760137767e-05,
      "learning_rate": 1.7661980356012877e-05,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 0.3729813919173703,
      "grad_norm": 1.9106080799247138e-05,
      "learning_rate": 1.763446776900432e-05,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 0.3770800885318469,
      "grad_norm": 1.6315223547280766e-05,
      "learning_rate": 1.7606955181995765e-05,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 0.3811787851463235,
      "grad_norm": 1.947652162925806e-05,
      "learning_rate": 1.757944259498721e-05,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 0.38527748176080007,
      "grad_norm": 1.780220009095501e-05,
      "learning_rate": 1.7551930007978653e-05,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 0.38937617837527666,
      "grad_norm": 1.0587064025457948e-05,
      "learning_rate": 1.7524417420970094e-05,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 0.39347487498975325,
      "grad_norm": 1.092712045647204e-05,
      "learning_rate": 1.7496904833961538e-05,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 0.39757357160422985,
      "grad_norm": 1.4532132809108589e-05,
      "learning_rate": 1.746939224695298e-05,
      "loss": 0.0,
      "step": 9700
    },
    {
      "epoch": 0.40167226821870644,
      "grad_norm": 2.0965930161764845e-05,
      "learning_rate": 1.7441879659944425e-05,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 0.40577096483318303,
      "grad_norm": 6.416525593522238e-06,
      "learning_rate": 1.741436707293587e-05,
      "loss": 0.0,
      "step": 9900
    },
    {
      "epoch": 0.40986966144765963,
      "grad_norm": 9.134096217167098e-06,
      "learning_rate": 1.7386854485927313e-05,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 0.4139683580621362,
      "grad_norm": 6.6722896008286625e-06,
      "learning_rate": 1.735961702478884e-05,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 0.4180670546766128,
      "grad_norm": 1.0696072422433645e-05,
      "learning_rate": 1.7332104437780285e-05,
      "loss": 0.0,
      "step": 10200
    },
    {
      "epoch": 0.4221657512910894,
      "grad_norm": 5.5403984333679546e-06,
      "learning_rate": 1.730459185077173e-05,
      "loss": 0.0,
      "step": 10300
    },
    {
      "epoch": 0.42626444790556606,
      "grad_norm": 6.410939477063948e-06,
      "learning_rate": 1.7277079263763173e-05,
      "loss": 0.0,
      "step": 10400
    },
    {
      "epoch": 0.43036314452004265,
      "grad_norm": 7.240937520691659e-06,
      "learning_rate": 1.7249566676754617e-05,
      "loss": 0.0,
      "step": 10500
    },
    {
      "epoch": 0.43446184113451924,
      "grad_norm": 6.1312994148465805e-06,
      "learning_rate": 1.722205408974606e-05,
      "loss": 0.0,
      "step": 10600
    },
    {
      "epoch": 0.43856053774899584,
      "grad_norm": 7.466697752533946e-06,
      "learning_rate": 1.7194541502737502e-05,
      "loss": 0.0,
      "step": 10700
    },
    {
      "epoch": 0.44265923436347243,
      "grad_norm": 4.779641585628269e-06,
      "learning_rate": 1.7167028915728946e-05,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 0.446757930977949,
      "grad_norm": 3.0506947950925678e-05,
      "learning_rate": 1.7139516328720393e-05,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 0.4508566275924256,
      "grad_norm": 6.998360731813591e-06,
      "learning_rate": 1.7112003741711837e-05,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 0.4549553242069022,
      "grad_norm": 2.7642020086204866e-06,
      "learning_rate": 1.7084491154703277e-05,
      "loss": 0.0,
      "step": 11100
    },
    {
      "epoch": 0.4590540208213788,
      "grad_norm": 4.812299266632181e-06,
      "learning_rate": 1.705697856769472e-05,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 0.4631527174358554,
      "grad_norm": 4.172309218120063e-06,
      "learning_rate": 1.7029465980686165e-05,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 0.467251414050332,
      "grad_norm": 4.263796654413454e-06,
      "learning_rate": 1.700195339367761e-05,
      "loss": 0.0,
      "step": 11400
    },
    {
      "epoch": 0.4713501106648086,
      "grad_norm": 3.283910473328433e-06,
      "learning_rate": 1.6974440806669053e-05,
      "loss": 0.0,
      "step": 11500
    },
    {
      "epoch": 0.4754488072792852,
      "grad_norm": 3.0793944461038336e-06,
      "learning_rate": 1.6946928219660497e-05,
      "loss": 0.0,
      "step": 11600
    },
    {
      "epoch": 0.4795475038937618,
      "grad_norm": 3.800503918682807e-06,
      "learning_rate": 1.6919415632651938e-05,
      "loss": 0.0,
      "step": 11700
    },
    {
      "epoch": 0.48364620050823837,
      "grad_norm": 4.670107500714948e-06,
      "learning_rate": 1.689190304564338e-05,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 0.48774489712271496,
      "grad_norm": 3.208534735676949e-06,
      "learning_rate": 1.686439045863483e-05,
      "loss": 0.0,
      "step": 11900
    },
    {
      "epoch": 0.49184359373719155,
      "grad_norm": 3.91311459679855e-06,
      "learning_rate": 1.683687787162627e-05,
      "loss": 0.0,
      "step": 12000
    },
    {
      "epoch": 0.49594229035166815,
      "grad_norm": 1.6128184370245435e-06,
      "learning_rate": 1.68096404104878e-05,
      "loss": 0.0,
      "step": 12100
    },
    {
      "epoch": 0.5000409869661447,
      "grad_norm": 1.9744306882785168e-06,
      "learning_rate": 1.6782127823479245e-05,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 0.5041396835806213,
      "grad_norm": 1.259396412933711e-06,
      "learning_rate": 1.6754615236470685e-05,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 0.5082383801950979,
      "grad_norm": 1.656871177146968e-06,
      "learning_rate": 1.672710264946213e-05,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 0.5123370768095745,
      "grad_norm": 2.3084958229446784e-06,
      "learning_rate": 1.6699590062453573e-05,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 0.5164357734240511,
      "grad_norm": 2.661792450453504e-06,
      "learning_rate": 1.6672077475445017e-05,
      "loss": 0.0,
      "step": 12600
    },
    {
      "epoch": 0.5205344700385277,
      "grad_norm": 3.7376489672169555e-06,
      "learning_rate": 1.664456488843646e-05,
      "loss": 0.0,
      "step": 12700
    },
    {
      "epoch": 0.5246331666530043,
      "grad_norm": 2.8046367788192583e-06,
      "learning_rate": 1.6617052301427905e-05,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 0.5287318632674809,
      "grad_norm": 1.367968252452556e-06,
      "learning_rate": 1.658953971441935e-05,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 0.5328305598819575,
      "grad_norm": 2.385922698522336e-06,
      "learning_rate": 1.6562027127410793e-05,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 0.5369292564964341,
      "grad_norm": 9.795130608836189e-07,
      "learning_rate": 1.6534514540402237e-05,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 0.5410279531109107,
      "grad_norm": 2.162188820875599e-06,
      "learning_rate": 1.650700195339368e-05,
      "loss": 0.0,
      "step": 13200
    },
    {
      "epoch": 0.5451266497253874,
      "grad_norm": 2.3244997464644257e-06,
      "learning_rate": 1.647948936638512e-05,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 0.549225346339864,
      "grad_norm": 1.9845651877403725e-06,
      "learning_rate": 1.6451976779376565e-05,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 0.5533240429543406,
      "grad_norm": 1.5946407074807212e-06,
      "learning_rate": 1.642446419236801e-05,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 0.5574227395688172,
      "grad_norm": 7.102077574927534e-07,
      "learning_rate": 1.6396951605359453e-05,
      "loss": 0.0,
      "step": 13600
    },
    {
      "epoch": 0.5615214361832938,
      "grad_norm": 8.059268452598189e-07,
      "learning_rate": 1.6369439018350897e-05,
      "loss": 0.0,
      "step": 13700
    },
    {
      "epoch": 0.5656201327977703,
      "grad_norm": 5.167013341633719e-07,
      "learning_rate": 1.634192643134234e-05,
      "loss": 0.0,
      "step": 13800
    },
    {
      "epoch": 0.5697188294122469,
      "grad_norm": 1.0245312296319753e-06,
      "learning_rate": 1.631441384433378e-05,
      "loss": 0.0,
      "step": 13900
    },
    {
      "epoch": 0.5738175260267235,
      "grad_norm": 8.992996072265669e-07,
      "learning_rate": 1.6286901257325226e-05,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 0.5779162226412001,
      "grad_norm": 6.468116566793469e-07,
      "learning_rate": 1.6259663796186757e-05,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 0.5820149192556767,
      "grad_norm": 1.2813527519028867e-06,
      "learning_rate": 1.62321512091782e-05,
      "loss": 0.0,
      "step": 14200
    },
    {
      "epoch": 0.5861136158701533,
      "grad_norm": 6.732965971423255e-07,
      "learning_rate": 1.6204638622169645e-05,
      "loss": 0.0,
      "step": 14300
    },
    {
      "epoch": 0.5902123124846299,
      "grad_norm": 1.0902026588155422e-06,
      "learning_rate": 1.617712603516109e-05,
      "loss": 0.0,
      "step": 14400
    },
    {
      "epoch": 0.5943110090991065,
      "grad_norm": 4.5102237322680594e-07,
      "learning_rate": 1.614961344815253e-05,
      "loss": 0.0,
      "step": 14500
    },
    {
      "epoch": 0.5984097057135831,
      "grad_norm": 1.2407646181600285e-06,
      "learning_rate": 1.6122100861143973e-05,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 0.6025084023280597,
      "grad_norm": 3.9925197370394017e-07,
      "learning_rate": 1.6094588274135417e-05,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 0.6066070989425363,
      "grad_norm": 6.002121608617017e-07,
      "learning_rate": 1.606707568712686e-05,
      "loss": 0.0,
      "step": 14800
    },
    {
      "epoch": 0.6107057955570129,
      "grad_norm": 4.418512560278032e-07,
      "learning_rate": 1.6039563100118305e-05,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 0.6148044921714895,
      "grad_norm": 4.5724172537120467e-07,
      "learning_rate": 1.601205051310975e-05,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 0.6189031887859661,
      "grad_norm": 2.797591207581718e-07,
      "learning_rate": 1.5984537926101193e-05,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 0.6230018854004427,
      "grad_norm": 4.0724975747252756e-07,
      "learning_rate": 1.5957025339092637e-05,
      "loss": 0.0,
      "step": 15200
    },
    {
      "epoch": 0.6271005820149193,
      "grad_norm": 4.0943820067695924e-07,
      "learning_rate": 1.592951275208408e-05,
      "loss": 0.0,
      "step": 15300
    },
    {
      "epoch": 0.6311992786293958,
      "grad_norm": 3.815211755409109e-07,
      "learning_rate": 1.5902000165075525e-05,
      "loss": 0.0,
      "step": 15400
    },
    {
      "epoch": 0.6352979752438724,
      "grad_norm": 8.624808174317877e-07,
      "learning_rate": 1.5874487578066965e-05,
      "loss": 0.0,
      "step": 15500
    },
    {
      "epoch": 0.639396671858349,
      "grad_norm": 2.612056846373889e-07,
      "learning_rate": 1.584697499105841e-05,
      "loss": 0.0,
      "step": 15600
    },
    {
      "epoch": 0.6434953684728256,
      "grad_norm": 3.602934839364025e-07,
      "learning_rate": 1.5819462404049853e-05,
      "loss": 0.0,
      "step": 15700
    },
    {
      "epoch": 0.6475940650873022,
      "grad_norm": 4.2150210788349796e-07,
      "learning_rate": 1.5791949817041297e-05,
      "loss": 0.0,
      "step": 15800
    },
    {
      "epoch": 0.6516927617017788,
      "grad_norm": 3.666085319764534e-07,
      "learning_rate": 1.576443723003274e-05,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 0.6557914583162554,
      "grad_norm": 3.15023783059587e-07,
      "learning_rate": 1.5736924643024185e-05,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 0.659890154930732,
      "grad_norm": 2.3322516540247307e-07,
      "learning_rate": 1.5709687181885713e-05,
      "loss": 0.0,
      "step": 16100
    },
    {
      "epoch": 0.6639888515452086,
      "grad_norm": 2.324830603583905e-07,
      "learning_rate": 1.5682174594877157e-05,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 0.6680875481596852,
      "grad_norm": 3.164322208704107e-07,
      "learning_rate": 1.56546620078686e-05,
      "loss": 0.0,
      "step": 16300
    },
    {
      "epoch": 0.6721862447741618,
      "grad_norm": 3.4355684874753933e-07,
      "learning_rate": 1.5627149420860045e-05,
      "loss": 0.0,
      "step": 16400
    },
    {
      "epoch": 0.6762849413886384,
      "grad_norm": 4.0226007058663527e-07,
      "learning_rate": 1.559963683385149e-05,
      "loss": 0.0,
      "step": 16500
    },
    {
      "epoch": 0.680383638003115,
      "grad_norm": 2.5217573806912696e-07,
      "learning_rate": 1.5572124246842933e-05,
      "loss": 0.0,
      "step": 16600
    },
    {
      "epoch": 0.6844823346175916,
      "grad_norm": 2.2882942118940264e-07,
      "learning_rate": 1.5544611659834377e-05,
      "loss": 0.0,
      "step": 16700
    },
    {
      "epoch": 0.6885810312320682,
      "grad_norm": 1.3157664398022462e-06,
      "learning_rate": 1.5517099072825817e-05,
      "loss": 0.0,
      "step": 16800
    },
    {
      "epoch": 0.6926797278465447,
      "grad_norm": 2.0047258431077353e-07,
      "learning_rate": 1.548958648581726e-05,
      "loss": 0.0,
      "step": 16900
    },
    {
      "epoch": 0.6967784244610215,
      "grad_norm": 3.0147603524710576e-07,
      "learning_rate": 1.546207389880871e-05,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 0.700877121075498,
      "grad_norm": 6.685969538011705e-07,
      "learning_rate": 1.543456131180015e-05,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 0.7049758176899746,
      "grad_norm": 2.9769384468636417e-07,
      "learning_rate": 1.5407048724791593e-05,
      "loss": 0.0,
      "step": 17200
    },
    {
      "epoch": 0.7090745143044512,
      "grad_norm": 3.265835459842492e-07,
      "learning_rate": 1.5379536137783037e-05,
      "loss": 0.0,
      "step": 17300
    },
    {
      "epoch": 0.7131732109189278,
      "grad_norm": 2.8641963467634923e-07,
      "learning_rate": 1.535202355077448e-05,
      "loss": 0.0,
      "step": 17400
    },
    {
      "epoch": 0.7172719075334044,
      "grad_norm": 1.750763516383813e-07,
      "learning_rate": 1.5324510963765925e-05,
      "loss": 0.0,
      "step": 17500
    },
    {
      "epoch": 0.721370604147881,
      "grad_norm": 2.661769542555703e-07,
      "learning_rate": 1.529699837675737e-05,
      "loss": 0.0,
      "step": 17600
    },
    {
      "epoch": 0.7254693007623576,
      "grad_norm": 2.3154781558787363e-07,
      "learning_rate": 1.526948578974881e-05,
      "loss": 0.0,
      "step": 17700
    },
    {
      "epoch": 0.7295679973768342,
      "grad_norm": 2.0573784809130302e-07,
      "learning_rate": 1.5241973202740255e-05,
      "loss": 0.0,
      "step": 17800
    },
    {
      "epoch": 0.7336666939913108,
      "grad_norm": 1.325119427519894e-07,
      "learning_rate": 1.5214460615731699e-05,
      "loss": 0.0,
      "step": 17900
    },
    {
      "epoch": 0.7377653906057874,
      "grad_norm": 8.878353696673003e-08,
      "learning_rate": 1.5186948028723143e-05,
      "loss": 0.0,
      "step": 18000
    },
    {
      "epoch": 0.741864087220264,
      "grad_norm": NaN,
      "learning_rate": 1.5159710567584671e-05,
      "loss": 0.0,
      "step": 18100
    },
    {
      "epoch": 0.7459627838347406,
      "grad_norm": 1.5100523853561754e-07,
      "learning_rate": 1.5132197980576115e-05,
      "loss": 0.0,
      "step": 18200
    },
    {
      "epoch": 0.7500614804492172,
      "grad_norm": 1.2742195565351722e-07,
      "learning_rate": 1.5104685393567557e-05,
      "loss": 0.0,
      "step": 18300
    },
    {
      "epoch": 0.7541601770636938,
      "grad_norm": 1.215947662558392e-07,
      "learning_rate": 1.5077172806559001e-05,
      "loss": 0.0,
      "step": 18400
    },
    {
      "epoch": 0.7582588736781704,
      "grad_norm": 1.7815085584516055e-07,
      "learning_rate": 1.5049660219550447e-05,
      "loss": 0.0,
      "step": 18500
    },
    {
      "epoch": 0.762357570292647,
      "grad_norm": 1.2027608420339675e-07,
      "learning_rate": 1.502214763254189e-05,
      "loss": 0.0,
      "step": 18600
    },
    {
      "epoch": 0.7664562669071235,
      "grad_norm": 1.5398146047118644e-07,
      "learning_rate": 1.4994635045533333e-05,
      "loss": 0.0,
      "step": 18700
    },
    {
      "epoch": 0.7705549635216001,
      "grad_norm": 1.5530717689671292e-07,
      "learning_rate": 1.4967122458524777e-05,
      "loss": 0.0,
      "step": 18800
    },
    {
      "epoch": 0.7746536601360767,
      "grad_norm": 1.8816386671005603e-07,
      "learning_rate": 1.493960987151622e-05,
      "loss": 0.0,
      "step": 18900
    },
    {
      "epoch": 0.7787523567505533,
      "grad_norm": 1.0715602627442422e-07,
      "learning_rate": 1.4912097284507663e-05,
      "loss": 0.0,
      "step": 19000
    },
    {
      "epoch": 0.7828510533650299,
      "grad_norm": 2.4394142883465975e-07,
      "learning_rate": 1.4884584697499107e-05,
      "loss": 0.0,
      "step": 19100
    },
    {
      "epoch": 0.7869497499795065,
      "grad_norm": 1.0594072819003486e-07,
      "learning_rate": 1.4857072110490551e-05,
      "loss": 0.0,
      "step": 19200
    },
    {
      "epoch": 0.7910484465939831,
      "grad_norm": 2.1707344899368763e-07,
      "learning_rate": 1.4829559523481993e-05,
      "loss": 0.0,
      "step": 19300
    },
    {
      "epoch": 0.7951471432084597,
      "grad_norm": 3.802363934823916e-08,
      "learning_rate": 1.4802046936473437e-05,
      "loss": 0.0,
      "step": 19400
    },
    {
      "epoch": 0.7992458398229363,
      "grad_norm": 7.434096005454194e-08,
      "learning_rate": 1.4774534349464881e-05,
      "loss": 0.0,
      "step": 19500
    },
    {
      "epoch": 0.8033445364374129,
      "grad_norm": 1.5806107001026248e-07,
      "learning_rate": 1.4747021762456323e-05,
      "loss": 0.0,
      "step": 19600
    },
    {
      "epoch": 0.8074432330518895,
      "grad_norm": 5.472062980516057e-08,
      "learning_rate": 1.4719509175447769e-05,
      "loss": 0.0,
      "step": 19700
    },
    {
      "epoch": 0.8115419296663661,
      "grad_norm": 1.457522813552714e-07,
      "learning_rate": 1.4691996588439213e-05,
      "loss": 0.0,
      "step": 19800
    },
    {
      "epoch": 0.8156406262808427,
      "grad_norm": 6.408702546423228e-08,
      "learning_rate": 1.4664484001430657e-05,
      "loss": 0.0,
      "step": 19900
    },
    {
      "epoch": 0.8197393228953193,
      "grad_norm": 6.010994724192642e-08,
      "learning_rate": 1.4636971414422099e-05,
      "loss": 0.0,
      "step": 20000
    },
    {
      "epoch": 0.8238380195097958,
      "grad_norm": 8.33808257993951e-08,
      "learning_rate": 1.4609458827413543e-05,
      "loss": 0.0,
      "step": 20100
    },
    {
      "epoch": 0.8279367161242724,
      "grad_norm": 7.409883551190433e-08,
      "learning_rate": 1.4582221366275071e-05,
      "loss": 0.0,
      "step": 20200
    },
    {
      "epoch": 0.832035412738749,
      "grad_norm": 3.677886795117047e-08,
      "learning_rate": 1.4554708779266515e-05,
      "loss": 0.0,
      "step": 20300
    },
    {
      "epoch": 0.8361341093532256,
      "grad_norm": 2.91711131694683e-07,
      "learning_rate": 1.4527196192257959e-05,
      "loss": 0.0,
      "step": 20400
    },
    {
      "epoch": 0.8402328059677022,
      "grad_norm": 4.713180601356726e-08,
      "learning_rate": 1.4499683605249405e-05,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 0.8443315025821788,
      "grad_norm": 6.500243898699409e-08,
      "learning_rate": 1.4472171018240845e-05,
      "loss": 0.0,
      "step": 20600
    },
    {
      "epoch": 0.8484301991966554,
      "grad_norm": 4.485424653921655e-08,
      "learning_rate": 1.444465843123229e-05,
      "loss": 0.0,
      "step": 20700
    },
    {
      "epoch": 0.8525288958111321,
      "grad_norm": 5.217434306814539e-08,
      "learning_rate": 1.4417145844223735e-05,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 0.8566275924256087,
      "grad_norm": 4.4419806499718106e-08,
      "learning_rate": 1.4389633257215177e-05,
      "loss": 0.0,
      "step": 20900
    },
    {
      "epoch": 0.8607262890400853,
      "grad_norm": 9.347398588488431e-08,
      "learning_rate": 1.4362120670206621e-05,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 0.8648249856545619,
      "grad_norm": 3.137995818747186e-08,
      "learning_rate": 1.4334608083198065e-05,
      "loss": 0.0,
      "step": 21100
    },
    {
      "epoch": 0.8689236822690385,
      "grad_norm": 1.21631501315278e-07,
      "learning_rate": 1.4307095496189507e-05,
      "loss": 0.0,
      "step": 21200
    },
    {
      "epoch": 0.8730223788835151,
      "grad_norm": 4.076438386846348e-08,
      "learning_rate": 1.4279582909180951e-05,
      "loss": 0.0,
      "step": 21300
    },
    {
      "epoch": 0.8771210754979917,
      "grad_norm": 5.3860201632005555e-08,
      "learning_rate": 1.4252070322172395e-05,
      "loss": 0.0,
      "step": 21400
    },
    {
      "epoch": 0.8812197721124683,
      "grad_norm": 2.862461556674134e-08,
      "learning_rate": 1.4224557735163837e-05,
      "loss": 0.0,
      "step": 21500
    },
    {
      "epoch": 0.8853184687269449,
      "grad_norm": 3.021209238340816e-08,
      "learning_rate": 1.4197045148155281e-05,
      "loss": 0.0,
      "step": 21600
    },
    {
      "epoch": 0.8894171653414215,
      "grad_norm": 4.786187801641972e-08,
      "learning_rate": 1.4169532561146727e-05,
      "loss": 0.0,
      "step": 21700
    },
    {
      "epoch": 0.893515861955898,
      "grad_norm": 3.653776659007235e-08,
      "learning_rate": 1.414201997413817e-05,
      "loss": 0.0,
      "step": 21800
    },
    {
      "epoch": 0.8976145585703746,
      "grad_norm": 4.8212523751089975e-08,
      "learning_rate": 1.4114507387129613e-05,
      "loss": 0.0,
      "step": 21900
    },
    {
      "epoch": 0.9017132551848512,
      "grad_norm": 5.2743981626690584e-08,
      "learning_rate": 1.4086994800121057e-05,
      "loss": 0.0,
      "step": 22000
    },
    {
      "epoch": 0.9058119517993278,
      "grad_norm": 3.013926175299275e-08,
      "learning_rate": 1.40594822131125e-05,
      "loss": 0.0,
      "step": 22100
    },
    {
      "epoch": 0.9099106484138044,
      "grad_norm": 2.8587896494514098e-08,
      "learning_rate": 1.4032244751974029e-05,
      "loss": 0.0,
      "step": 22200
    },
    {
      "epoch": 0.914009345028281,
      "grad_norm": 2.384099317964683e-08,
      "learning_rate": 1.4004732164965473e-05,
      "loss": 0.0,
      "step": 22300
    },
    {
      "epoch": 0.9181080416427576,
      "grad_norm": 3.967823758443956e-08,
      "learning_rate": 1.3977219577956917e-05,
      "loss": 0.0,
      "step": 22400
    },
    {
      "epoch": 0.9222067382572342,
      "grad_norm": 2.6084622462008156e-08,
      "learning_rate": 1.3949706990948359e-05,
      "loss": 0.0,
      "step": 22500
    },
    {
      "epoch": 0.9263054348717108,
      "grad_norm": 3.355734534693511e-08,
      "learning_rate": 1.3922194403939805e-05,
      "loss": 0.0,
      "step": 22600
    },
    {
      "epoch": 0.9304041314861874,
      "grad_norm": 2.4811457777218493e-08,
      "learning_rate": 1.3894681816931249e-05,
      "loss": 0.0,
      "step": 22700
    },
    {
      "epoch": 0.934502828100664,
      "grad_norm": 1.7982543454309052e-08,
      "learning_rate": 1.386716922992269e-05,
      "loss": 0.0,
      "step": 22800
    },
    {
      "epoch": 0.9386015247151406,
      "grad_norm": 3.803292969450922e-08,
      "learning_rate": 1.3839656642914135e-05,
      "loss": 0.0,
      "step": 22900
    },
    {
      "epoch": 0.9427002213296172,
      "grad_norm": 2.6236566696979935e-08,
      "learning_rate": 1.3812144055905579e-05,
      "loss": 0.0,
      "step": 23000
    },
    {
      "epoch": 0.9467989179440938,
      "grad_norm": 1.8520557532042403e-08,
      "learning_rate": 1.3784631468897021e-05,
      "loss": 0.0,
      "step": 23100
    },
    {
      "epoch": 0.9508976145585704,
      "grad_norm": 5.74781822137993e-08,
      "learning_rate": 1.3757118881888465e-05,
      "loss": 0.0,
      "step": 23200
    },
    {
      "epoch": 0.954996311173047,
      "grad_norm": 1.6800820290541196e-08,
      "learning_rate": 1.3729606294879909e-05,
      "loss": 0.0,
      "step": 23300
    },
    {
      "epoch": 0.9590950077875235,
      "grad_norm": 2.7341393149526994e-08,
      "learning_rate": 1.3702093707871351e-05,
      "loss": 0.0,
      "step": 23400
    },
    {
      "epoch": 0.9631937044020001,
      "grad_norm": 1.859971021644924e-08,
      "learning_rate": 1.3674581120862795e-05,
      "loss": 0.0,
      "step": 23500
    },
    {
      "epoch": 0.9672924010164767,
      "grad_norm": 1.8905620180476035e-08,
      "learning_rate": 1.3647068533854239e-05,
      "loss": 0.0,
      "step": 23600
    },
    {
      "epoch": 0.9713910976309533,
      "grad_norm": 2.162992451815171e-08,
      "learning_rate": 1.3619555946845685e-05,
      "loss": 0.0,
      "step": 23700
    },
    {
      "epoch": 0.9754897942454299,
      "grad_norm": 2.001525167827367e-08,
      "learning_rate": 1.3592043359837127e-05,
      "loss": 0.0,
      "step": 23800
    },
    {
      "epoch": 0.9795884908599065,
      "grad_norm": 1.2958111028638086e-08,
      "learning_rate": 1.356453077282857e-05,
      "loss": 0.0,
      "step": 23900
    },
    {
      "epoch": 0.9836871874743831,
      "grad_norm": 2.2555754597419764e-08,
      "learning_rate": 1.3537018185820015e-05,
      "loss": 0.0,
      "step": 24000
    },
    {
      "epoch": 0.9877858840888597,
      "grad_norm": 1.0232287905864723e-08,
      "learning_rate": 1.3509505598811457e-05,
      "loss": 0.0,
      "step": 24100
    },
    {
      "epoch": 0.9918845807033363,
      "grad_norm": 3.571945583757952e-08,
      "learning_rate": 1.3482268137672987e-05,
      "loss": 0.0,
      "step": 24200
    },
    {
      "epoch": 0.9959832773178129,
      "grad_norm": 2.132557241907307e-08,
      "learning_rate": 1.345475555066443e-05,
      "loss": 0.0,
      "step": 24300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 1.0,
      "eval_f1": 1.0,
      "eval_loss": 0.0,
      "eval_precision": 1.0,
      "eval_recall": 1.0,
      "eval_runtime": 475.2856,
      "eval_samples_per_second": 102.667,
      "eval_steps_per_second": 12.834,
      "step": 24398
    },
    {
      "epoch": 1.0000819739322895,
      "grad_norm": 1.7832871179734866e-08,
      "learning_rate": 1.3427242963655873e-05,
      "loss": 0.0,
      "step": 24400
    },
    {
      "epoch": 1.0041806705467662,
      "grad_norm": 3.990341213011561e-08,
      "learning_rate": 1.3399730376647317e-05,
      "loss": 0.0,
      "step": 24500
    },
    {
      "epoch": 1.0082793671612427,
      "grad_norm": 1.5422706667322927e-08,
      "learning_rate": 1.3372217789638762e-05,
      "loss": 0.0,
      "step": 24600
    },
    {
      "epoch": 1.0123780637757194,
      "grad_norm": 2.0255832566817844e-08,
      "learning_rate": 1.3344705202630203e-05,
      "loss": 0.0,
      "step": 24700
    },
    {
      "epoch": 1.0164767603901959,
      "grad_norm": 8.764170722486142e-09,
      "learning_rate": 1.3317192615621649e-05,
      "loss": 0.0,
      "step": 24800
    },
    {
      "epoch": 1.0205754570046726,
      "grad_norm": 1.3861623848754334e-08,
      "learning_rate": 1.3289680028613093e-05,
      "loss": 0.0,
      "step": 24900
    },
    {
      "epoch": 1.024674153619149,
      "grad_norm": 1.5631769656465622e-08,
      "learning_rate": 1.3262167441604535e-05,
      "loss": 0.0,
      "step": 25000
    },
    {
      "epoch": 1.0287728502336257,
      "grad_norm": 1.387573522748653e-08,
      "learning_rate": 1.3234654854595979e-05,
      "loss": 0.0,
      "step": 25100
    },
    {
      "epoch": 1.0328715468481022,
      "grad_norm": 1.7297395515925018e-08,
      "learning_rate": 1.3207142267587423e-05,
      "loss": 0.0,
      "step": 25200
    },
    {
      "epoch": 1.036970243462579,
      "grad_norm": 3.830494321732658e-08,
      "learning_rate": 1.3179629680578865e-05,
      "loss": 0.0,
      "step": 25300
    },
    {
      "epoch": 1.0410689400770554,
      "grad_norm": 1.4321190455746091e-08,
      "learning_rate": 1.3152117093570309e-05,
      "loss": 0.0,
      "step": 25400
    },
    {
      "epoch": 1.0451676366915321,
      "grad_norm": 8.148831831533698e-09,
      "learning_rate": 1.3124604506561753e-05,
      "loss": 0.0,
      "step": 25500
    },
    {
      "epoch": 1.0492663333060086,
      "grad_norm": 6.149306841507496e-08,
      "learning_rate": 1.3097091919553197e-05,
      "loss": 0.0,
      "step": 25600
    },
    {
      "epoch": 1.0533650299204853,
      "grad_norm": 1.5602225289512717e-08,
      "learning_rate": 1.3069579332544639e-05,
      "loss": 0.0,
      "step": 25700
    },
    {
      "epoch": 1.0574637265349618,
      "grad_norm": 1.836637508745298e-08,
      "learning_rate": 1.3042066745536085e-05,
      "loss": 0.0,
      "step": 25800
    },
    {
      "epoch": 1.0615624231494385,
      "grad_norm": 8.256688666108403e-09,
      "learning_rate": 1.3014554158527529e-05,
      "loss": 0.0,
      "step": 25900
    },
    {
      "epoch": 1.065661119763915,
      "grad_norm": 1.0312776410614788e-08,
      "learning_rate": 1.298704157151897e-05,
      "loss": 0.0,
      "step": 26000
    },
    {
      "epoch": 1.0697598163783917,
      "grad_norm": 8.163276277173281e-09,
      "learning_rate": 1.2959528984510415e-05,
      "loss": 0.0,
      "step": 26100
    },
    {
      "epoch": 1.0738585129928682,
      "grad_norm": 5.81111292419223e-09,
      "learning_rate": 1.2932291523371945e-05,
      "loss": 0.0,
      "step": 26200
    },
    {
      "epoch": 1.0779572096073449,
      "grad_norm": 7.141558455714403e-09,
      "learning_rate": 1.2904778936363387e-05,
      "loss": 0.0,
      "step": 26300
    },
    {
      "epoch": 1.0820559062218216,
      "grad_norm": 1.2705005048019302e-08,
      "learning_rate": 1.287726634935483e-05,
      "loss": 0.0,
      "step": 26400
    },
    {
      "epoch": 1.086154602836298,
      "grad_norm": 6.348326753169431e-09,
      "learning_rate": 1.2849753762346275e-05,
      "loss": 0.0,
      "step": 26500
    },
    {
      "epoch": 1.0902532994507745,
      "grad_norm": 2.3476902200059158e-08,
      "learning_rate": 1.2822241175337717e-05,
      "loss": 0.0,
      "step": 26600
    },
    {
      "epoch": 1.0943519960652512,
      "grad_norm": 7.944421120953393e-09,
      "learning_rate": 1.279472858832916e-05,
      "loss": 0.0,
      "step": 26700
    },
    {
      "epoch": 1.098450692679728,
      "grad_norm": 1.2232622914609692e-08,
      "learning_rate": 1.2767216001320606e-05,
      "loss": 0.0,
      "step": 26800
    },
    {
      "epoch": 1.1025493892942044,
      "grad_norm": 1.2187115316919517e-07,
      "learning_rate": 1.2739703414312049e-05,
      "loss": 0.0,
      "step": 26900
    },
    {
      "epoch": 1.1066480859086811,
      "grad_norm": 7.106423005609486e-09,
      "learning_rate": 1.2712190827303493e-05,
      "loss": 0.0,
      "step": 27000
    },
    {
      "epoch": 1.1107467825231576,
      "grad_norm": 4.279303134069323e-09,
      "learning_rate": 1.2684678240294937e-05,
      "loss": 0.0,
      "step": 27100
    },
    {
      "epoch": 1.1148454791376343,
      "grad_norm": 1.186657705432026e-08,
      "learning_rate": 1.2657165653286379e-05,
      "loss": 0.0,
      "step": 27200
    },
    {
      "epoch": 1.1189441757521108,
      "grad_norm": 1.06739657113053e-08,
      "learning_rate": 1.2629653066277823e-05,
      "loss": 0.0,
      "step": 27300
    },
    {
      "epoch": 1.1230428723665875,
      "grad_norm": 4.356506710934127e-09,
      "learning_rate": 1.2602140479269267e-05,
      "loss": 0.0,
      "step": 27400
    },
    {
      "epoch": 1.127141568981064,
      "grad_norm": 4.291655919530513e-09,
      "learning_rate": 1.257462789226071e-05,
      "loss": 0.0,
      "step": 27500
    },
    {
      "epoch": 1.1312402655955407,
      "grad_norm": 1.2575407382087178e-08,
      "learning_rate": 1.2547115305252153e-05,
      "loss": 0.0,
      "step": 27600
    },
    {
      "epoch": 1.1353389622100172,
      "grad_norm": 4.8870494318009605e-09,
      "learning_rate": 1.2519602718243597e-05,
      "loss": 0.0,
      "step": 27700
    },
    {
      "epoch": 1.1394376588244939,
      "grad_norm": 7.201724105954099e-09,
      "learning_rate": 1.2492090131235042e-05,
      "loss": 0.0,
      "step": 27800
    },
    {
      "epoch": 1.1435363554389704,
      "grad_norm": 1.3512297947215757e-08,
      "learning_rate": 1.2464577544226483e-05,
      "loss": 0.0,
      "step": 27900
    },
    {
      "epoch": 1.147635052053447,
      "grad_norm": 3.099976719767028e-09,
      "learning_rate": 1.2437064957217929e-05,
      "loss": 0.0,
      "step": 28000
    },
    {
      "epoch": 1.1517337486679236,
      "grad_norm": 5.57703794257236e-09,
      "learning_rate": 1.2409552370209373e-05,
      "loss": 0.0,
      "step": 28100
    },
    {
      "epoch": 1.1558324452824003,
      "grad_norm": 8.27991541996198e-09,
      "learning_rate": 1.23823149090709e-05,
      "loss": 0.0,
      "step": 28200
    },
    {
      "epoch": 1.1599311418968767,
      "grad_norm": 4.608421644292093e-09,
      "learning_rate": 1.2354802322062345e-05,
      "loss": 0.0,
      "step": 28300
    },
    {
      "epoch": 1.1640298385113534,
      "grad_norm": 8.466344070257037e-09,
      "learning_rate": 1.2327289735053789e-05,
      "loss": 0.0,
      "step": 28400
    },
    {
      "epoch": 1.16812853512583,
      "grad_norm": 9.631645703223057e-09,
      "learning_rate": 1.229977714804523e-05,
      "loss": 0.0,
      "step": 28500
    },
    {
      "epoch": 1.1722272317403066,
      "grad_norm": 6.9027827898082705e-09,
      "learning_rate": 1.2272264561036675e-05,
      "loss": 0.0,
      "step": 28600
    },
    {
      "epoch": 1.1763259283547831,
      "grad_norm": 5.961279470056979e-09,
      "learning_rate": 1.224475197402812e-05,
      "loss": 0.0,
      "step": 28700
    },
    {
      "epoch": 1.1804246249692598,
      "grad_norm": 9.752382013061833e-09,
      "learning_rate": 1.2217239387019561e-05,
      "loss": 0.0,
      "step": 28800
    },
    {
      "epoch": 1.1845233215837363,
      "grad_norm": 6.945557018411819e-09,
      "learning_rate": 1.2189726800011007e-05,
      "loss": 0.0,
      "step": 28900
    },
    {
      "epoch": 1.188622018198213,
      "grad_norm": 6.636079241673087e-09,
      "learning_rate": 1.216221421300245e-05,
      "loss": 0.0,
      "step": 29000
    },
    {
      "epoch": 1.1927207148126895,
      "grad_norm": 4.615553717002285e-09,
      "learning_rate": 1.2134701625993893e-05,
      "loss": 0.0,
      "step": 29100
    },
    {
      "epoch": 1.1968194114271662,
      "grad_norm": 3.2548250761266218e-09,
      "learning_rate": 1.2107189038985337e-05,
      "loss": 0.0,
      "step": 29200
    },
    {
      "epoch": 1.2009181080416427,
      "grad_norm": 9.075452389595284e-09,
      "learning_rate": 1.207967645197678e-05,
      "loss": 0.0,
      "step": 29300
    },
    {
      "epoch": 1.2050168046561194,
      "grad_norm": 5.450743412183101e-09,
      "learning_rate": 1.2052163864968225e-05,
      "loss": 0.0,
      "step": 29400
    },
    {
      "epoch": 1.2091155012705959,
      "grad_norm": 3.991103891820558e-09,
      "learning_rate": 1.2024651277959667e-05,
      "loss": 0.0,
      "step": 29500
    },
    {
      "epoch": 1.2132141978850726,
      "grad_norm": 3.4798655068613016e-09,
      "learning_rate": 1.199713869095111e-05,
      "loss": 0.0,
      "step": 29600
    },
    {
      "epoch": 1.217312894499549,
      "grad_norm": 5.33872901442578e-09,
      "learning_rate": 1.1969626103942555e-05,
      "loss": 0.0,
      "step": 29700
    },
    {
      "epoch": 1.2214115911140258,
      "grad_norm": 9.728538863384983e-09,
      "learning_rate": 1.1942113516933997e-05,
      "loss": 0.0,
      "step": 29800
    },
    {
      "epoch": 1.2255102877285022,
      "grad_norm": 3.89942789169595e-09,
      "learning_rate": 1.1914600929925442e-05,
      "loss": 0.0,
      "step": 29900
    },
    {
      "epoch": 1.229608984342979,
      "grad_norm": 3.3610280780749235e-08,
      "learning_rate": 1.1887088342916886e-05,
      "loss": 0.0,
      "step": 30000
    },
    {
      "epoch": 1.2337076809574556,
      "grad_norm": 6.990525491801236e-09,
      "learning_rate": 1.1859575755908329e-05,
      "loss": 0.0,
      "step": 30100
    },
    {
      "epoch": 1.2378063775719321,
      "grad_norm": 9.582840299060535e-09,
      "learning_rate": 1.1832338294769858e-05,
      "loss": 0.0,
      "step": 30200
    },
    {
      "epoch": 1.2419050741864086,
      "grad_norm": 4.854195267967043e-09,
      "learning_rate": 1.1804825707761302e-05,
      "loss": 0.0,
      "step": 30300
    },
    {
      "epoch": 1.2460037708008853,
      "grad_norm": 4.576073298068195e-09,
      "learning_rate": 1.1777313120752745e-05,
      "loss": 0.0,
      "step": 30400
    },
    {
      "epoch": 1.250102467415362,
      "grad_norm": 9.830483094219744e-09,
      "learning_rate": 1.1749800533744189e-05,
      "loss": 0.0,
      "step": 30500
    },
    {
      "epoch": 1.2542011640298385,
      "grad_norm": 6.774445893142911e-09,
      "learning_rate": 1.1722287946735633e-05,
      "loss": 0.0,
      "step": 30600
    },
    {
      "epoch": 1.258299860644315,
      "grad_norm": 2.86493473389271e-09,
      "learning_rate": 1.1694775359727075e-05,
      "loss": 0.0,
      "step": 30700
    },
    {
      "epoch": 1.2623985572587917,
      "grad_norm": 2.3886583822019247e-09,
      "learning_rate": 1.1667262772718519e-05,
      "loss": 0.0,
      "step": 30800
    },
    {
      "epoch": 1.2664972538732684,
      "grad_norm": 1.8922179378932924e-09,
      "learning_rate": 1.1639750185709964e-05,
      "loss": 0.0,
      "step": 30900
    },
    {
      "epoch": 1.2705959504877449,
      "grad_norm": 6.695756393781949e-09,
      "learning_rate": 1.1612237598701407e-05,
      "loss": 0.0,
      "step": 31000
    },
    {
      "epoch": 1.2746946471022214,
      "grad_norm": 2.2377035779896914e-09,
      "learning_rate": 1.158472501169285e-05,
      "loss": 0.0,
      "step": 31100
    },
    {
      "epoch": 1.278793343716698,
      "grad_norm": 3.2291431750763877e-09,
      "learning_rate": 1.1557212424684294e-05,
      "loss": 0.0,
      "step": 31200
    },
    {
      "epoch": 1.2828920403311748,
      "grad_norm": 3.2622775592017206e-09,
      "learning_rate": 1.1529699837675738e-05,
      "loss": 0.0,
      "step": 31300
    },
    {
      "epoch": 1.2869907369456512,
      "grad_norm": 4.435344980180389e-09,
      "learning_rate": 1.150218725066718e-05,
      "loss": 0.0,
      "step": 31400
    },
    {
      "epoch": 1.291089433560128,
      "grad_norm": 5.269257030704466e-09,
      "learning_rate": 1.1474674663658625e-05,
      "loss": 0.0,
      "step": 31500
    },
    {
      "epoch": 1.2951881301746044,
      "grad_norm": 3.8342520269907254e-09,
      "learning_rate": 1.1447162076650068e-05,
      "loss": 0.0,
      "step": 31600
    },
    {
      "epoch": 1.2992868267890811,
      "grad_norm": 5.3167994451541745e-09,
      "learning_rate": 1.141964948964151e-05,
      "loss": 0.0,
      "step": 31700
    },
    {
      "epoch": 1.3033855234035576,
      "grad_norm": 3.4625011746669543e-09,
      "learning_rate": 1.1392136902632955e-05,
      "loss": 0.0,
      "step": 31800
    },
    {
      "epoch": 1.3074842200180343,
      "grad_norm": 2.4673409981801342e-08,
      "learning_rate": 1.13646243156244e-05,
      "loss": 0.0,
      "step": 31900
    },
    {
      "epoch": 1.3115829166325108,
      "grad_norm": 1.7682938446839103e-09,
      "learning_rate": 1.133711172861584e-05,
      "loss": 0.0,
      "step": 32000
    },
    {
      "epoch": 1.3156816132469875,
      "grad_norm": 8.371500825887779e-09,
      "learning_rate": 1.1309599141607286e-05,
      "loss": 0.0,
      "step": 32100
    },
    {
      "epoch": 1.319780309861464,
      "grad_norm": 4.718043289386742e-09,
      "learning_rate": 1.1282361680468816e-05,
      "loss": 0.0,
      "step": 32200
    },
    {
      "epoch": 1.3238790064759407,
      "grad_norm": 2.5029434080892088e-09,
      "learning_rate": 1.1254849093460259e-05,
      "loss": 0.0,
      "step": 32300
    },
    {
      "epoch": 1.3279777030904172,
      "grad_norm": 5.170433414747322e-09,
      "learning_rate": 1.1227336506451702e-05,
      "loss": 0.0,
      "step": 32400
    },
    {
      "epoch": 1.3320763997048939,
      "grad_norm": 3.3489471196190834e-09,
      "learning_rate": 1.1199823919443146e-05,
      "loss": 0.0,
      "step": 32500
    },
    {
      "epoch": 1.3361750963193704,
      "grad_norm": 5.163641514371875e-09,
      "learning_rate": 1.1172311332434589e-05,
      "loss": 0.0,
      "step": 32600
    },
    {
      "epoch": 1.340273792933847,
      "grad_norm": 2.796016307371474e-09,
      "learning_rate": 1.1144798745426033e-05,
      "loss": 0.0,
      "step": 32700
    },
    {
      "epoch": 1.3443724895483236,
      "grad_norm": 3.295483885779049e-09,
      "learning_rate": 1.1117286158417478e-05,
      "loss": 0.0,
      "step": 32800
    },
    {
      "epoch": 1.3484711861628003,
      "grad_norm": 5.921763523986101e-09,
      "learning_rate": 1.1089773571408919e-05,
      "loss": 0.0,
      "step": 32900
    },
    {
      "epoch": 1.3525698827772767,
      "grad_norm": 2.50834508719322e-09,
      "learning_rate": 1.1062260984400364e-05,
      "loss": 0.0,
      "step": 33000
    },
    {
      "epoch": 1.3566685793917534,
      "grad_norm": 2.227995565817764e-09,
      "learning_rate": 1.1034748397391808e-05,
      "loss": 0.0,
      "step": 33100
    },
    {
      "epoch": 1.36076727600623,
      "grad_norm": 3.4297780171499426e-09,
      "learning_rate": 1.1007235810383252e-05,
      "loss": 0.0,
      "step": 33200
    },
    {
      "epoch": 1.3648659726207066,
      "grad_norm": 1.7253716233511796e-09,
      "learning_rate": 1.0979723223374695e-05,
      "loss": 0.0,
      "step": 33300
    },
    {
      "epoch": 1.3689646692351833,
      "grad_norm": 3.982624008358471e-09,
      "learning_rate": 1.0952210636366138e-05,
      "loss": 0.0,
      "step": 33400
    },
    {
      "epoch": 1.3730633658496598,
      "grad_norm": 2.4412931676209837e-09,
      "learning_rate": 1.0924698049357582e-05,
      "loss": 0.0,
      "step": 33500
    },
    {
      "epoch": 1.3771620624641363,
      "grad_norm": 3.1380946730052983e-09,
      "learning_rate": 1.0897185462349025e-05,
      "loss": 0.0,
      "step": 33600
    },
    {
      "epoch": 1.381260759078613,
      "grad_norm": 4.375945827916894e-09,
      "learning_rate": 1.0869672875340469e-05,
      "loss": 0.0,
      "step": 33700
    },
    {
      "epoch": 1.3853594556930897,
      "grad_norm": 2.8198239299115357e-09,
      "learning_rate": 1.0842160288331912e-05,
      "loss": 0.0,
      "step": 33800
    },
    {
      "epoch": 1.3894581523075662,
      "grad_norm": 3.324057029630012e-09,
      "learning_rate": 1.0814647701323355e-05,
      "loss": 0.0,
      "step": 33900
    },
    {
      "epoch": 1.3935568489220427,
      "grad_norm": 5.0932640327516765e-09,
      "learning_rate": 1.07871351143148e-05,
      "loss": 0.0,
      "step": 34000
    },
    {
      "epoch": 1.3976555455365194,
      "grad_norm": 6.388274798041493e-09,
      "learning_rate": 1.0759622527306244e-05,
      "loss": 0.0,
      "step": 34100
    },
    {
      "epoch": 1.401754242150996,
      "grad_norm": 3.935229031526433e-09,
      "learning_rate": 1.0732385066167772e-05,
      "loss": 0.0,
      "step": 34200
    },
    {
      "epoch": 1.4058529387654726,
      "grad_norm": 2.1230808222583164e-09,
      "learning_rate": 1.0704872479159216e-05,
      "loss": 0.0,
      "step": 34300
    },
    {
      "epoch": 1.409951635379949,
      "grad_norm": 4.695430266821177e-09,
      "learning_rate": 1.067735989215066e-05,
      "loss": 0.0,
      "step": 34400
    },
    {
      "epoch": 1.4140503319944258,
      "grad_norm": 2.3757713574212858e-09,
      "learning_rate": 1.0649847305142103e-05,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 1.4181490286089025,
      "grad_norm": 3.2691138684981524e-09,
      "learning_rate": 1.0622334718133546e-05,
      "loss": 0.0,
      "step": 34600
    },
    {
      "epoch": 1.422247725223379,
      "grad_norm": 3.9392844541907834e-09,
      "learning_rate": 1.059482213112499e-05,
      "loss": 0.0,
      "step": 34700
    },
    {
      "epoch": 1.4263464218378554,
      "grad_norm": 1.1081103812315973e-09,
      "learning_rate": 1.0567309544116433e-05,
      "loss": 0.0,
      "step": 34800
    },
    {
      "epoch": 1.4304451184523321,
      "grad_norm": 1.793931003746252e-09,
      "learning_rate": 1.0539796957107877e-05,
      "loss": 0.0,
      "step": 34900
    },
    {
      "epoch": 1.4345438150668088,
      "grad_norm": 9.853073024146397e-09,
      "learning_rate": 1.0512284370099322e-05,
      "loss": 0.0,
      "step": 35000
    },
    {
      "epoch": 1.4386425116812853,
      "grad_norm": 1.901512947100059e-09,
      "learning_rate": 1.0484771783090766e-05,
      "loss": 0.0,
      "step": 35100
    },
    {
      "epoch": 1.442741208295762,
      "grad_norm": 3.4934668491359844e-09,
      "learning_rate": 1.0457259196082208e-05,
      "loss": 0.0,
      "step": 35200
    },
    {
      "epoch": 1.4468399049102385,
      "grad_norm": 1.0092684465945467e-09,
      "learning_rate": 1.0429746609073652e-05,
      "loss": 0.0,
      "step": 35300
    },
    {
      "epoch": 1.4509386015247152,
      "grad_norm": 1.9837735898420306e-09,
      "learning_rate": 1.0402234022065096e-05,
      "loss": 0.0,
      "step": 35400
    },
    {
      "epoch": 1.4550372981391917,
      "grad_norm": 4.726618652028947e-09,
      "learning_rate": 1.0374721435056538e-05,
      "loss": 0.0,
      "step": 35500
    },
    {
      "epoch": 1.4591359947536684,
      "grad_norm": 2.985357516749332e-09,
      "learning_rate": 1.0347208848047982e-05,
      "loss": 0.0,
      "step": 35600
    },
    {
      "epoch": 1.4632346913681449,
      "grad_norm": 4.293196909088692e-09,
      "learning_rate": 1.0319696261039426e-05,
      "loss": 0.0,
      "step": 35700
    },
    {
      "epoch": 1.4673333879826216,
      "grad_norm": 1.6903738409013158e-09,
      "learning_rate": 1.0292183674030869e-05,
      "loss": 0.0,
      "step": 35800
    },
    {
      "epoch": 1.471432084597098,
      "grad_norm": 2.355399209008624e-09,
      "learning_rate": 1.0264671087022313e-05,
      "loss": 0.0,
      "step": 35900
    },
    {
      "epoch": 1.4755307812115748,
      "grad_norm": 1.6195941254792956e-09,
      "learning_rate": 1.0237158500013758e-05,
      "loss": 0.0,
      "step": 36000
    },
    {
      "epoch": 1.4796294778260513,
      "grad_norm": 2.893765893574596e-09,
      "learning_rate": 1.0209645913005202e-05,
      "loss": 0.0,
      "step": 36100
    },
    {
      "epoch": 1.483728174440528,
      "grad_norm": 2.9122728673058873e-09,
      "learning_rate": 1.018240845186673e-05,
      "loss": 0.0,
      "step": 36200
    },
    {
      "epoch": 1.4878268710550044,
      "grad_norm": 7.981948435542563e-09,
      "learning_rate": 1.0154895864858174e-05,
      "loss": 0.0,
      "step": 36300
    },
    {
      "epoch": 1.4919255676694811,
      "grad_norm": 1.9370576254118532e-09,
      "learning_rate": 1.0127383277849616e-05,
      "loss": 0.0,
      "step": 36400
    },
    {
      "epoch": 1.4960242642839576,
      "grad_norm": 5.734896113551713e-09,
      "learning_rate": 1.009987069084106e-05,
      "loss": 0.0,
      "step": 36500
    },
    {
      "epoch": 1.5001229608984343,
      "grad_norm": 3.5332592407399943e-09,
      "learning_rate": 1.0072358103832504e-05,
      "loss": 0.0,
      "step": 36600
    },
    {
      "epoch": 1.504221657512911,
      "grad_norm": 1.9745649559865797e-09,
      "learning_rate": 1.0044845516823947e-05,
      "loss": 0.0,
      "step": 36700
    },
    {
      "epoch": 1.5083203541273875,
      "grad_norm": 3.5825349353757474e-09,
      "learning_rate": 1.001733292981539e-05,
      "loss": 0.0,
      "step": 36800
    },
    {
      "epoch": 1.512419050741864,
      "grad_norm": 3.1247746612450555e-09,
      "learning_rate": 9.989820342806834e-06,
      "loss": 0.0,
      "step": 36900
    },
    {
      "epoch": 1.5165177473563407,
      "grad_norm": 4.851416157691801e-09,
      "learning_rate": 9.962307755798278e-06,
      "loss": 0.0,
      "step": 37000
    },
    {
      "epoch": 1.5206164439708174,
      "grad_norm": 1.2888093925411681e-09,
      "learning_rate": 9.934795168789722e-06,
      "loss": 0.0,
      "step": 37100
    },
    {
      "epoch": 1.524715140585294,
      "grad_norm": 2.137524157674875e-09,
      "learning_rate": 9.907282581781166e-06,
      "loss": 0.0,
      "step": 37200
    },
    {
      "epoch": 1.5288138371997704,
      "grad_norm": 3.728300335126278e-09,
      "learning_rate": 9.879769994772608e-06,
      "loss": 0.0,
      "step": 37300
    },
    {
      "epoch": 1.532912533814247,
      "grad_norm": 1.332248200647257e-09,
      "learning_rate": 9.852257407764052e-06,
      "loss": 0.0,
      "step": 37400
    },
    {
      "epoch": 1.5370112304287238,
      "grad_norm": 7.655349687496482e-10,
      "learning_rate": 9.824744820755496e-06,
      "loss": 0.0,
      "step": 37500
    },
    {
      "epoch": 1.5411099270432003,
      "grad_norm": 4.296471622922127e-09,
      "learning_rate": 9.79723223374694e-06,
      "loss": 0.0,
      "step": 37600
    },
    {
      "epoch": 1.5452086236576767,
      "grad_norm": 1.0956086704538848e-08,
      "learning_rate": 9.769719646738384e-06,
      "loss": 0.0,
      "step": 37700
    },
    {
      "epoch": 1.5493073202721535,
      "grad_norm": 4.13838829871338e-09,
      "learning_rate": 9.742207059729826e-06,
      "loss": 0.0,
      "step": 37800
    },
    {
      "epoch": 1.5534060168866302,
      "grad_norm": 2.085425387932105e-09,
      "learning_rate": 9.71469447272127e-06,
      "loss": 0.0,
      "step": 37900
    },
    {
      "epoch": 1.5575047135011066,
      "grad_norm": 1.6574409622549524e-09,
      "learning_rate": 9.687181885712714e-06,
      "loss": 0.0,
      "step": 38000
    },
    {
      "epoch": 1.5616034101155831,
      "grad_norm": 1.0893714819104616e-09,
      "learning_rate": 9.659669298704158e-06,
      "loss": 0.0,
      "step": 38100
    },
    {
      "epoch": 1.5657021067300598,
      "grad_norm": 2.970364398890979e-09,
      "learning_rate": 9.632431837565686e-06,
      "loss": 0.0,
      "step": 38200
    },
    {
      "epoch": 1.5698008033445365,
      "grad_norm": 3.3114480046947392e-09,
      "learning_rate": 9.60491925055713e-06,
      "loss": 0.0,
      "step": 38300
    },
    {
      "epoch": 1.573899499959013,
      "grad_norm": 7.230703258365168e-10,
      "learning_rate": 9.577406663548574e-06,
      "loss": 0.0,
      "step": 38400
    },
    {
      "epoch": 1.5779981965734895,
      "grad_norm": 1.5167098688095848e-09,
      "learning_rate": 9.549894076540018e-06,
      "loss": 0.0,
      "step": 38500
    },
    {
      "epoch": 1.5820968931879662,
      "grad_norm": 2.7490869580759636e-09,
      "learning_rate": 9.522381489531462e-06,
      "loss": 0.0,
      "step": 38600
    },
    {
      "epoch": 1.586195589802443,
      "grad_norm": 1.039206054542774e-09,
      "learning_rate": 9.494868902522904e-06,
      "loss": 0.0,
      "step": 38700
    },
    {
      "epoch": 1.5902942864169194,
      "grad_norm": 1.9794113015336734e-09,
      "learning_rate": 9.467356315514348e-06,
      "loss": 0.0,
      "step": 38800
    },
    {
      "epoch": 1.5943929830313959,
      "grad_norm": 3.0349902591098044e-09,
      "learning_rate": 9.439843728505792e-06,
      "loss": 0.0,
      "step": 38900
    },
    {
      "epoch": 1.5984916796458726,
      "grad_norm": 1.3077551264117915e-09,
      "learning_rate": 9.412331141497236e-06,
      "loss": 0.0,
      "step": 39000
    },
    {
      "epoch": 1.6025903762603493,
      "grad_norm": 2.716799007984605e-09,
      "learning_rate": 9.38481855448868e-06,
      "loss": 0.0,
      "step": 39100
    },
    {
      "epoch": 1.6066890728748258,
      "grad_norm": 2.148100142207454e-09,
      "learning_rate": 9.357305967480122e-06,
      "loss": 0.0,
      "step": 39200
    },
    {
      "epoch": 1.6107877694893022,
      "grad_norm": 1.195295973310806e-09,
      "learning_rate": 9.329793380471566e-06,
      "loss": 0.0,
      "step": 39300
    },
    {
      "epoch": 1.614886466103779,
      "grad_norm": 1.8402660506566804e-09,
      "learning_rate": 9.30228079346301e-06,
      "loss": 0.0,
      "step": 39400
    },
    {
      "epoch": 1.6189851627182557,
      "grad_norm": 4.291706101611226e-09,
      "learning_rate": 9.274768206454454e-06,
      "loss": 0.0,
      "step": 39500
    },
    {
      "epoch": 1.6230838593327321,
      "grad_norm": 4.582862533908383e-09,
      "learning_rate": 9.247255619445898e-06,
      "loss": 0.0,
      "step": 39600
    },
    {
      "epoch": 1.6271825559472088,
      "grad_norm": 1.6425254489860208e-09,
      "learning_rate": 9.21974303243734e-06,
      "loss": 0.0,
      "step": 39700
    },
    {
      "epoch": 1.6312812525616853,
      "grad_norm": 2.2476909222746144e-09,
      "learning_rate": 9.192230445428784e-06,
      "loss": 0.0,
      "step": 39800
    },
    {
      "epoch": 1.635379949176162,
      "grad_norm": 2.3250978919975296e-09,
      "learning_rate": 9.164717858420228e-06,
      "loss": 0.0,
      "step": 39900
    },
    {
      "epoch": 1.6394786457906387,
      "grad_norm": 4.183245749800335e-09,
      "learning_rate": 9.137205271411672e-06,
      "loss": 0.0,
      "step": 40000
    },
    {
      "epoch": 1.6435773424051152,
      "grad_norm": 1.0448176768207418e-09,
      "learning_rate": 9.109692684403116e-06,
      "loss": 0.0,
      "step": 40100
    },
    {
      "epoch": 1.6476760390195917,
      "grad_norm": 9.971456993440597e-10,
      "learning_rate": 9.082455223264644e-06,
      "loss": 0.0,
      "step": 40200
    },
    {
      "epoch": 1.6517747356340684,
      "grad_norm": 5.22309928641107e-09,
      "learning_rate": 9.054942636256088e-06,
      "loss": 0.0,
      "step": 40300
    },
    {
      "epoch": 1.655873432248545,
      "grad_norm": 2.0087218555175923e-09,
      "learning_rate": 9.027430049247532e-06,
      "loss": 0.0,
      "step": 40400
    },
    {
      "epoch": 1.6599721288630216,
      "grad_norm": 1.3167463785990208e-09,
      "learning_rate": 8.999917462238974e-06,
      "loss": 0.0,
      "step": 40500
    },
    {
      "epoch": 1.664070825477498,
      "grad_norm": 1.2755416722853852e-09,
      "learning_rate": 8.972404875230418e-06,
      "loss": 0.0,
      "step": 40600
    },
    {
      "epoch": 1.6681695220919748,
      "grad_norm": 1.806208849153279e-09,
      "learning_rate": 8.944892288221862e-06,
      "loss": 0.0,
      "step": 40700
    },
    {
      "epoch": 1.6722682187064515,
      "grad_norm": 7.59926621629603e-10,
      "learning_rate": 8.917379701213306e-06,
      "loss": 0.0,
      "step": 40800
    },
    {
      "epoch": 1.676366915320928,
      "grad_norm": 1.4246787083393997e-09,
      "learning_rate": 8.88986711420475e-06,
      "loss": 0.0,
      "step": 40900
    },
    {
      "epoch": 1.6804656119354044,
      "grad_norm": 1.4420302729689638e-09,
      "learning_rate": 8.862354527196192e-06,
      "loss": 0.0,
      "step": 41000
    },
    {
      "epoch": 1.6845643085498812,
      "grad_norm": 1.4870564779556616e-09,
      "learning_rate": 8.834841940187636e-06,
      "loss": 0.0,
      "step": 41100
    },
    {
      "epoch": 1.6886630051643579,
      "grad_norm": 2.3250568137456185e-09,
      "learning_rate": 8.80732935317908e-06,
      "loss": 0.0,
      "step": 41200
    },
    {
      "epoch": 1.6927617017788343,
      "grad_norm": 8.204624202257094e-10,
      "learning_rate": 8.779816766170524e-06,
      "loss": 0.0,
      "step": 41300
    },
    {
      "epoch": 1.6968603983933108,
      "grad_norm": 3.711609464218668e-09,
      "learning_rate": 8.752304179161968e-06,
      "loss": 0.0,
      "step": 41400
    },
    {
      "epoch": 1.7009590950077875,
      "grad_norm": 2.382965380576252e-09,
      "learning_rate": 8.72479159215341e-06,
      "loss": 0.0,
      "step": 41500
    },
    {
      "epoch": 1.7050577916222642,
      "grad_norm": 1.4220570276890498e-09,
      "learning_rate": 8.697279005144854e-06,
      "loss": 0.0,
      "step": 41600
    },
    {
      "epoch": 1.7091564882367407,
      "grad_norm": 1.5507642947554245e-09,
      "learning_rate": 8.669766418136298e-06,
      "loss": 0.0,
      "step": 41700
    },
    {
      "epoch": 1.7132551848512172,
      "grad_norm": 1.7172230304396408e-09,
      "learning_rate": 8.642253831127742e-06,
      "loss": 0.0,
      "step": 41800
    },
    {
      "epoch": 1.717353881465694,
      "grad_norm": 2.4018131927761033e-09,
      "learning_rate": 8.614741244119186e-06,
      "loss": 0.0,
      "step": 41900
    },
    {
      "epoch": 1.7214525780801706,
      "grad_norm": 6.972314947617519e-10,
      "learning_rate": 8.587228657110628e-06,
      "loss": 0.0,
      "step": 42000
    },
    {
      "epoch": 1.725551274694647,
      "grad_norm": 6.797080120968246e-10,
      "learning_rate": 8.559716070102072e-06,
      "loss": 0.0,
      "step": 42100
    },
    {
      "epoch": 1.7296499713091236,
      "grad_norm": 1.775945279725022e-09,
      "learning_rate": 8.532478608963602e-06,
      "loss": 0.0,
      "step": 42200
    },
    {
      "epoch": 1.7337486679236003,
      "grad_norm": 1.0030887231948782e-09,
      "learning_rate": 8.504966021955046e-06,
      "loss": 0.0,
      "step": 42300
    },
    {
      "epoch": 1.737847364538077,
      "grad_norm": 4.059968805592007e-09,
      "learning_rate": 8.477453434946488e-06,
      "loss": 0.0,
      "step": 42400
    },
    {
      "epoch": 1.7419460611525535,
      "grad_norm": 2.305906798838464e-09,
      "learning_rate": 8.449940847937932e-06,
      "loss": 0.0,
      "step": 42500
    },
    {
      "epoch": 1.74604475776703,
      "grad_norm": 1.144618955173371e-09,
      "learning_rate": 8.422428260929376e-06,
      "loss": 0.0,
      "step": 42600
    },
    {
      "epoch": 1.7501434543815066,
      "grad_norm": 2.6020552379435458e-09,
      "learning_rate": 8.39491567392082e-06,
      "loss": 0.0,
      "step": 42700
    },
    {
      "epoch": 1.7542421509959834,
      "grad_norm": 1.1552840906148276e-09,
      "learning_rate": 8.367403086912264e-06,
      "loss": 0.0,
      "step": 42800
    },
    {
      "epoch": 1.7583408476104598,
      "grad_norm": 1.3088159445118208e-09,
      "learning_rate": 8.339890499903706e-06,
      "loss": 0.0,
      "step": 42900
    },
    {
      "epoch": 1.7624395442249363,
      "grad_norm": 1.3185097458290329e-08,
      "learning_rate": 8.31237791289515e-06,
      "loss": 0.0,
      "step": 43000
    },
    {
      "epoch": 1.766538240839413,
      "grad_norm": 7.797065770809297e-10,
      "learning_rate": 8.284865325886594e-06,
      "loss": 0.0,
      "step": 43100
    },
    {
      "epoch": 1.7706369374538897,
      "grad_norm": 2.3216009115145653e-09,
      "learning_rate": 8.257352738878038e-06,
      "loss": 0.0,
      "step": 43200
    },
    {
      "epoch": 1.7747356340683662,
      "grad_norm": 2.784856345527942e-09,
      "learning_rate": 8.229840151869482e-06,
      "loss": 0.0,
      "step": 43300
    },
    {
      "epoch": 1.7788343306828427,
      "grad_norm": 6.098954230537856e-09,
      "learning_rate": 8.202327564860924e-06,
      "loss": 0.0,
      "step": 43400
    },
    {
      "epoch": 1.7829330272973194,
      "grad_norm": 1.7748470471090627e-09,
      "learning_rate": 8.174814977852368e-06,
      "loss": 0.0,
      "step": 43500
    },
    {
      "epoch": 1.787031723911796,
      "grad_norm": 1.362961854489697e-09,
      "learning_rate": 8.147302390843812e-06,
      "loss": 0.0,
      "step": 43600
    },
    {
      "epoch": 1.7911304205262728,
      "grad_norm": 1.1952507872337037e-09,
      "learning_rate": 8.119789803835256e-06,
      "loss": 0.0,
      "step": 43700
    },
    {
      "epoch": 1.7952291171407493,
      "grad_norm": 1.2217457268093312e-08,
      "learning_rate": 8.0922772168267e-06,
      "loss": 0.0,
      "step": 43800
    },
    {
      "epoch": 1.7993278137552258,
      "grad_norm": 3.2027862584271816e-09,
      "learning_rate": 8.064764629818142e-06,
      "loss": 0.0,
      "step": 43900
    },
    {
      "epoch": 1.8034265103697025,
      "grad_norm": 6.801538776635141e-10,
      "learning_rate": 8.037252042809586e-06,
      "loss": 0.0,
      "step": 44000
    },
    {
      "epoch": 1.8075252069841792,
      "grad_norm": 8.382214367053109e-10,
      "learning_rate": 8.00973945580103e-06,
      "loss": 0.0,
      "step": 44100
    },
    {
      "epoch": 1.8116239035986557,
      "grad_norm": 5.9924136763811475e-09,
      "learning_rate": 7.98250199466256e-06,
      "loss": 0.0,
      "step": 44200
    },
    {
      "epoch": 1.8157226002131321,
      "grad_norm": 7.554424863442932e-10,
      "learning_rate": 7.954989407654002e-06,
      "loss": 0.0,
      "step": 44300
    },
    {
      "epoch": 1.8198212968276088,
      "grad_norm": 1.6599028818120587e-09,
      "learning_rate": 7.927476820645446e-06,
      "loss": 0.0,
      "step": 44400
    },
    {
      "epoch": 1.8239199934420856,
      "grad_norm": 7.568361493071052e-10,
      "learning_rate": 7.89996423363689e-06,
      "loss": 0.0,
      "step": 44500
    },
    {
      "epoch": 1.828018690056562,
      "grad_norm": 1.2610519295463973e-09,
      "learning_rate": 7.872451646628332e-06,
      "loss": 0.0,
      "step": 44600
    },
    {
      "epoch": 1.8321173866710385,
      "grad_norm": 3.721846164594922e-09,
      "learning_rate": 7.844939059619778e-06,
      "loss": 0.0,
      "step": 44700
    },
    {
      "epoch": 1.8362160832855152,
      "grad_norm": 7.00048852220192e-10,
      "learning_rate": 7.81742647261122e-06,
      "loss": 0.0,
      "step": 44800
    },
    {
      "epoch": 1.840314779899992,
      "grad_norm": 1.3128300668796555e-09,
      "learning_rate": 7.789913885602664e-06,
      "loss": 0.0,
      "step": 44900
    },
    {
      "epoch": 1.8444134765144684,
      "grad_norm": 1.0683669504629734e-09,
      "learning_rate": 7.762401298594108e-06,
      "loss": 0.0,
      "step": 45000
    },
    {
      "epoch": 1.848512173128945,
      "grad_norm": 3.670680204237442e-09,
      "learning_rate": 7.73488871158555e-06,
      "loss": 0.0,
      "step": 45100
    },
    {
      "epoch": 1.8526108697434216,
      "grad_norm": 1.7683613462438075e-09,
      "learning_rate": 7.707376124576996e-06,
      "loss": 0.0,
      "step": 45200
    },
    {
      "epoch": 1.8567095663578983,
      "grad_norm": 3.3533000820540337e-09,
      "learning_rate": 7.679863537568438e-06,
      "loss": 0.0,
      "step": 45300
    },
    {
      "epoch": 1.8608082629723748,
      "grad_norm": 1.498932533650077e-09,
      "learning_rate": 7.652350950559882e-06,
      "loss": 0.0,
      "step": 45400
    },
    {
      "epoch": 1.8649069595868513,
      "grad_norm": 3.103048706876166e-09,
      "learning_rate": 7.624838363551326e-06,
      "loss": 0.0,
      "step": 45500
    },
    {
      "epoch": 1.869005656201328,
      "grad_norm": 1.2739801436012499e-09,
      "learning_rate": 7.597325776542769e-06,
      "loss": 0.0,
      "step": 45600
    },
    {
      "epoch": 1.8731043528158047,
      "grad_norm": 2.9915665500368505e-09,
      "learning_rate": 7.569813189534213e-06,
      "loss": 0.0,
      "step": 45700
    },
    {
      "epoch": 1.8772030494302812,
      "grad_norm": 1.1140298683542937e-09,
      "learning_rate": 7.542300602525656e-06,
      "loss": 0.0,
      "step": 45800
    },
    {
      "epoch": 1.8813017460447576,
      "grad_norm": 8.36619440391928e-10,
      "learning_rate": 7.514788015517099e-06,
      "loss": 0.0,
      "step": 45900
    },
    {
      "epoch": 1.8854004426592343,
      "grad_norm": 9.252362209721809e-10,
      "learning_rate": 7.487275428508544e-06,
      "loss": 0.0,
      "step": 46000
    },
    {
      "epoch": 1.889499139273711,
      "grad_norm": 1.3740740767431703e-09,
      "learning_rate": 7.459762841499987e-06,
      "loss": 0.0,
      "step": 46100
    },
    {
      "epoch": 1.8935978358881875,
      "grad_norm": 1.4644540025088304e-09,
      "learning_rate": 7.432525380361516e-06,
      "loss": 0.0,
      "step": 46200
    },
    {
      "epoch": 1.897696532502664,
      "grad_norm": 9.833334146946981e-10,
      "learning_rate": 7.405012793352959e-06,
      "loss": 0.0,
      "step": 46300
    },
    {
      "epoch": 1.9017952291171407,
      "grad_norm": 1.2068823718180965e-09,
      "learning_rate": 7.377500206344404e-06,
      "loss": 0.0,
      "step": 46400
    },
    {
      "epoch": 1.9058939257316174,
      "grad_norm": 1.703803875763299e-09,
      "learning_rate": 7.349987619335847e-06,
      "loss": 0.0,
      "step": 46500
    },
    {
      "epoch": 1.909992622346094,
      "grad_norm": 1.0206813172430884e-09,
      "learning_rate": 7.322475032327291e-06,
      "loss": 0.0,
      "step": 46600
    },
    {
      "epoch": 1.9140913189605704,
      "grad_norm": 2.007959132299675e-09,
      "learning_rate": 7.294962445318734e-06,
      "loss": 0.0,
      "step": 46700
    },
    {
      "epoch": 1.918190015575047,
      "grad_norm": 9.907554776589222e-10,
      "learning_rate": 7.267449858310177e-06,
      "loss": 0.0,
      "step": 46800
    },
    {
      "epoch": 1.9222887121895238,
      "grad_norm": 1.1019724022176547e-09,
      "learning_rate": 7.239937271301622e-06,
      "loss": 0.0,
      "step": 46900
    },
    {
      "epoch": 1.9263874088040003,
      "grad_norm": 7.804587531801133e-10,
      "learning_rate": 7.212424684293065e-06,
      "loss": 0.0,
      "step": 47000
    },
    {
      "epoch": 1.9304861054184768,
      "grad_norm": 1.24604238038728e-09,
      "learning_rate": 7.184912097284509e-06,
      "loss": 0.0,
      "step": 47100
    },
    {
      "epoch": 1.9345848020329535,
      "grad_norm": 1.8570964765984854e-09,
      "learning_rate": 7.157399510275952e-06,
      "loss": 0.0,
      "step": 47200
    },
    {
      "epoch": 1.9386834986474302,
      "grad_norm": 3.6369016687132216e-09,
      "learning_rate": 7.129886923267395e-06,
      "loss": 0.0,
      "step": 47300
    },
    {
      "epoch": 1.9427821952619069,
      "grad_norm": 1.5449167500847238e-09,
      "learning_rate": 7.102374336258839e-06,
      "loss": 0.0,
      "step": 47400
    },
    {
      "epoch": 1.9468808918763834,
      "grad_norm": 2.285740041685358e-09,
      "learning_rate": 7.074861749250283e-06,
      "loss": 0.0,
      "step": 47500
    },
    {
      "epoch": 1.9509795884908598,
      "grad_norm": 1.446339270572139e-09,
      "learning_rate": 7.047349162241727e-06,
      "loss": 0.0,
      "step": 47600
    },
    {
      "epoch": 1.9550782851053365,
      "grad_norm": 6.381503103725095e-10,
      "learning_rate": 7.01983657523317e-06,
      "loss": 0.0,
      "step": 47700
    },
    {
      "epoch": 1.9591769817198132,
      "grad_norm": 1.496586632399044e-09,
      "learning_rate": 6.992323988224613e-06,
      "loss": 0.0,
      "step": 47800
    },
    {
      "epoch": 1.9632756783342897,
      "grad_norm": 6.912554972871021e-10,
      "learning_rate": 6.964811401216057e-06,
      "loss": 0.0,
      "step": 47900
    },
    {
      "epoch": 1.9673743749487662,
      "grad_norm": 1.9160404374218842e-09,
      "learning_rate": 6.9372988142075e-06,
      "loss": 0.0,
      "step": 48000
    },
    {
      "epoch": 1.971473071563243,
      "grad_norm": 1.079513367585605e-09,
      "learning_rate": 6.909786227198944e-06,
      "loss": 0.0,
      "step": 48100
    },
    {
      "epoch": 1.9755717681777196,
      "grad_norm": 2.1127459781666857e-09,
      "learning_rate": 6.882548766060473e-06,
      "loss": 0.0,
      "step": 48200
    },
    {
      "epoch": 1.979670464792196,
      "grad_norm": 1.3863512560163826e-09,
      "learning_rate": 6.855036179051917e-06,
      "loss": 0.0,
      "step": 48300
    },
    {
      "epoch": 1.9837691614066726,
      "grad_norm": 1.1704153202174439e-09,
      "learning_rate": 6.82752359204336e-06,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 1.9878678580211493,
      "grad_norm": 9.37687594237957e-10,
      "learning_rate": 6.800011005034805e-06,
      "loss": 0.0,
      "step": 48500
    },
    {
      "epoch": 1.991966554635626,
      "grad_norm": 6.494225712749824e-10,
      "learning_rate": 6.772498418026248e-06,
      "loss": 0.0,
      "step": 48600
    },
    {
      "epoch": 1.9960652512501025,
      "grad_norm": 1.7246676309312647e-09,
      "learning_rate": 6.744985831017691e-06,
      "loss": 0.0,
      "step": 48700
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 1.0,
      "eval_f1": 1.0,
      "eval_loss": 0.0,
      "eval_precision": 1.0,
      "eval_recall": 1.0,
      "eval_runtime": 468.4118,
      "eval_samples_per_second": 104.173,
      "eval_steps_per_second": 13.023,
      "step": 48796
    },
    {
      "epoch": 2.000163947864579,
      "grad_norm": 1.409763639159678e-09,
      "learning_rate": 6.717473244009135e-06,
      "loss": 0.0,
      "step": 48800
    },
    {
      "epoch": 2.0042626444790557,
      "grad_norm": 1.507937663625114e-09,
      "learning_rate": 6.689960657000578e-06,
      "loss": 0.0,
      "step": 48900
    },
    {
      "epoch": 2.0083613410935324,
      "grad_norm": 8.870053025411551e-10,
      "learning_rate": 6.662448069992023e-06,
      "loss": 0.0,
      "step": 49000
    },
    {
      "epoch": 2.012460037708009,
      "grad_norm": 8.373771120950835e-10,
      "learning_rate": 6.634935482983466e-06,
      "loss": 0.0,
      "step": 49100
    },
    {
      "epoch": 2.0165587343224853,
      "grad_norm": 9.221702290673761e-10,
      "learning_rate": 6.607422895974909e-06,
      "loss": 0.0,
      "step": 49200
    },
    {
      "epoch": 2.020657430936962,
      "grad_norm": 1.870352317467905e-09,
      "learning_rate": 6.579910308966353e-06,
      "loss": 0.0,
      "step": 49300
    },
    {
      "epoch": 2.0247561275514387,
      "grad_norm": 6.814144248856735e-10,
      "learning_rate": 6.552397721957796e-06,
      "loss": 0.0,
      "step": 49400
    },
    {
      "epoch": 2.0288548241659154,
      "grad_norm": 8.731643741377582e-10,
      "learning_rate": 6.524885134949241e-06,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 2.0329535207803917,
      "grad_norm": 5.218487308944475e-10,
      "learning_rate": 6.497372547940684e-06,
      "loss": 0.0,
      "step": 49600
    },
    {
      "epoch": 2.0370522173948684,
      "grad_norm": 9.072400608545195e-10,
      "learning_rate": 6.469859960932127e-06,
      "loss": 0.0,
      "step": 49700
    },
    {
      "epoch": 2.041150914009345,
      "grad_norm": 5.784267509412189e-10,
      "learning_rate": 6.442347373923571e-06,
      "loss": 0.0,
      "step": 49800
    },
    {
      "epoch": 2.045249610623822,
      "grad_norm": 1.2048303466016819e-09,
      "learning_rate": 6.414834786915014e-06,
      "loss": 0.0,
      "step": 49900
    },
    {
      "epoch": 2.049348307238298,
      "grad_norm": 1.1409487798985651e-09,
      "learning_rate": 6.387322199906457e-06,
      "loss": 0.0,
      "step": 50000
    },
    {
      "epoch": 2.053447003852775,
      "grad_norm": 3.3159524015502484e-09,
      "learning_rate": 6.359809612897902e-06,
      "loss": 0.0,
      "step": 50100
    },
    {
      "epoch": 2.0575457004672515,
      "grad_norm": 1.953753603345376e-09,
      "learning_rate": 6.332572151759431e-06,
      "loss": 0.0,
      "step": 50200
    },
    {
      "epoch": 2.061644397081728,
      "grad_norm": 1.2185982223300584e-09,
      "learning_rate": 6.305059564750874e-06,
      "loss": 0.0,
      "step": 50300
    },
    {
      "epoch": 2.0657430936962045,
      "grad_norm": 7.712880889521045e-10,
      "learning_rate": 6.277546977742318e-06,
      "loss": 0.0,
      "step": 50400
    },
    {
      "epoch": 2.069841790310681,
      "grad_norm": 8.118773986431904e-10,
      "learning_rate": 6.250034390733762e-06,
      "loss": 0.0,
      "step": 50500
    },
    {
      "epoch": 2.073940486925158,
      "grad_norm": 9.09829489526004e-10,
      "learning_rate": 6.222521803725205e-06,
      "loss": 0.0,
      "step": 50600
    },
    {
      "epoch": 2.0780391835396346,
      "grad_norm": 1.518035919190197e-09,
      "learning_rate": 6.195009216716649e-06,
      "loss": 0.0,
      "step": 50700
    },
    {
      "epoch": 2.082137880154111,
      "grad_norm": 5.868782793072569e-09,
      "learning_rate": 6.167496629708092e-06,
      "loss": 0.0,
      "step": 50800
    },
    {
      "epoch": 2.0862365767685875,
      "grad_norm": 1.2548958538971533e-09,
      "learning_rate": 6.139984042699536e-06,
      "loss": 0.0,
      "step": 50900
    },
    {
      "epoch": 2.0903352733830642,
      "grad_norm": 6.809303676469369e-10,
      "learning_rate": 6.112471455690979e-06,
      "loss": 0.0,
      "step": 51000
    },
    {
      "epoch": 2.094433969997541,
      "grad_norm": 3.5972822498564483e-09,
      "learning_rate": 6.084958868682423e-06,
      "loss": 0.0,
      "step": 51100
    },
    {
      "epoch": 2.098532666612017,
      "grad_norm": 7.961013515078719e-10,
      "learning_rate": 6.057446281673867e-06,
      "loss": 0.0,
      "step": 51200
    },
    {
      "epoch": 2.102631363226494,
      "grad_norm": 1.178352748709699e-09,
      "learning_rate": 6.02993369466531e-06,
      "loss": 0.0,
      "step": 51300
    },
    {
      "epoch": 2.1067300598409706,
      "grad_norm": 1.0205812861485697e-09,
      "learning_rate": 6.002421107656754e-06,
      "loss": 0.0,
      "step": 51400
    },
    {
      "epoch": 2.1108287564554473,
      "grad_norm": 2.45036724244585e-09,
      "learning_rate": 5.974908520648197e-06,
      "loss": 0.0,
      "step": 51500
    },
    {
      "epoch": 2.1149274530699236,
      "grad_norm": 9.082889995681853e-10,
      "learning_rate": 5.947395933639641e-06,
      "loss": 0.0,
      "step": 51600
    },
    {
      "epoch": 2.1190261496844003,
      "grad_norm": 1.8713839367023866e-09,
      "learning_rate": 5.919883346631085e-06,
      "loss": 0.0,
      "step": 51700
    },
    {
      "epoch": 2.123124846298877,
      "grad_norm": 7.53080431348252e-10,
      "learning_rate": 5.892370759622528e-06,
      "loss": 0.0,
      "step": 51800
    },
    {
      "epoch": 2.1272235429133537,
      "grad_norm": 2.6386473006567712e-09,
      "learning_rate": 5.864858172613971e-06,
      "loss": 0.0,
      "step": 51900
    },
    {
      "epoch": 2.13132223952783,
      "grad_norm": 4.145333853955435e-09,
      "learning_rate": 5.837345585605415e-06,
      "loss": 0.0,
      "step": 52000
    },
    {
      "epoch": 2.1354209361423067,
      "grad_norm": 1.7213381831027164e-09,
      "learning_rate": 5.809832998596858e-06,
      "loss": 0.0,
      "step": 52100
    },
    {
      "epoch": 2.1395196327567834,
      "grad_norm": 1.9391921401989975e-09,
      "learning_rate": 5.782595537458388e-06,
      "loss": 0.0,
      "step": 52200
    },
    {
      "epoch": 2.14361832937126,
      "grad_norm": 3.96870625252177e-09,
      "learning_rate": 5.755082950449832e-06,
      "loss": 0.0,
      "step": 52300
    },
    {
      "epoch": 2.1477170259857363,
      "grad_norm": 6.42459641042592e-10,
      "learning_rate": 5.727570363441275e-06,
      "loss": 0.0,
      "step": 52400
    },
    {
      "epoch": 2.151815722600213,
      "grad_norm": 1.491191725655483e-09,
      "learning_rate": 5.700057776432718e-06,
      "loss": 0.0,
      "step": 52500
    },
    {
      "epoch": 2.1559144192146897,
      "grad_norm": 1.1482532702444814e-09,
      "learning_rate": 5.6725451894241626e-06,
      "loss": 0.0,
      "step": 52600
    },
    {
      "epoch": 2.1600131158291664,
      "grad_norm": 1.2172605146076876e-09,
      "learning_rate": 5.645032602415606e-06,
      "loss": 0.0,
      "step": 52700
    },
    {
      "epoch": 2.164111812443643,
      "grad_norm": 1.5926501228946677e-09,
      "learning_rate": 5.61752001540705e-06,
      "loss": 0.0,
      "step": 52800
    },
    {
      "epoch": 2.1682105090581194,
      "grad_norm": 1.4044080343111887e-09,
      "learning_rate": 5.590007428398493e-06,
      "loss": 0.0,
      "step": 52900
    },
    {
      "epoch": 2.172309205672596,
      "grad_norm": 1.3114902497335379e-09,
      "learning_rate": 5.562494841389936e-06,
      "loss": 0.0,
      "step": 53000
    },
    {
      "epoch": 2.176407902287073,
      "grad_norm": 1.0497399616227199e-09,
      "learning_rate": 5.5349822543813806e-06,
      "loss": 0.0,
      "step": 53100
    },
    {
      "epoch": 2.180506598901549,
      "grad_norm": 1.2877238164676896e-09,
      "learning_rate": 5.507469667372824e-06,
      "loss": 0.0,
      "step": 53200
    },
    {
      "epoch": 2.184605295516026,
      "grad_norm": 6.046669831505369e-10,
      "learning_rate": 5.479957080364267e-06,
      "loss": 0.0,
      "step": 53300
    },
    {
      "epoch": 2.1887039921305025,
      "grad_norm": 1.1021732415628094e-09,
      "learning_rate": 5.452444493355711e-06,
      "loss": 0.0,
      "step": 53400
    },
    {
      "epoch": 2.192802688744979,
      "grad_norm": 2.8857198852705324e-09,
      "learning_rate": 5.424931906347154e-06,
      "loss": 0.0,
      "step": 53500
    },
    {
      "epoch": 2.196901385359456,
      "grad_norm": 1.6509407174680746e-09,
      "learning_rate": 5.3974193193385985e-06,
      "loss": 0.0,
      "step": 53600
    },
    {
      "epoch": 2.201000081973932,
      "grad_norm": 9.139828893722779e-10,
      "learning_rate": 5.369906732330042e-06,
      "loss": 0.0,
      "step": 53700
    },
    {
      "epoch": 2.205098778588409,
      "grad_norm": 9.028658931597988e-10,
      "learning_rate": 5.342394145321485e-06,
      "loss": 0.0,
      "step": 53800
    },
    {
      "epoch": 2.2091974752028856,
      "grad_norm": 1.5067899150622566e-09,
      "learning_rate": 5.314881558312929e-06,
      "loss": 0.0,
      "step": 53900
    },
    {
      "epoch": 2.2132961718173623,
      "grad_norm": 9.786192967098373e-10,
      "learning_rate": 5.287368971304372e-06,
      "loss": 0.0,
      "step": 54000
    },
    {
      "epoch": 2.2173948684318385,
      "grad_norm": 1.2459453468949278e-09,
      "learning_rate": 5.2598563842958165e-06,
      "loss": 0.0,
      "step": 54100
    },
    {
      "epoch": 2.2214935650463152,
      "grad_norm": 1.1341483308058287e-09,
      "learning_rate": 5.2326189231573455e-06,
      "loss": 0.0,
      "step": 54200
    },
    {
      "epoch": 2.225592261660792,
      "grad_norm": 3.2948468398075192e-09,
      "learning_rate": 5.205106336148789e-06,
      "loss": 0.0,
      "step": 54300
    },
    {
      "epoch": 2.2296909582752686,
      "grad_norm": 3.4569349605106936e-09,
      "learning_rate": 5.177593749140232e-06,
      "loss": 0.0,
      "step": 54400
    },
    {
      "epoch": 2.233789654889745,
      "grad_norm": 1.200825328062649e-09,
      "learning_rate": 5.150081162131676e-06,
      "loss": 0.0,
      "step": 54500
    },
    {
      "epoch": 2.2378883515042216,
      "grad_norm": 1.3547530874902236e-09,
      "learning_rate": 5.122568575123119e-06,
      "loss": 0.0,
      "step": 54600
    },
    {
      "epoch": 2.2419870481186983,
      "grad_norm": 1.2413562400226397e-09,
      "learning_rate": 5.0950559881145635e-06,
      "loss": 0.0,
      "step": 54700
    },
    {
      "epoch": 2.246085744733175,
      "grad_norm": 5.915136713774416e-10,
      "learning_rate": 5.0675434011060066e-06,
      "loss": 0.0,
      "step": 54800
    },
    {
      "epoch": 2.2501844413476513,
      "grad_norm": 2.113568431383328e-09,
      "learning_rate": 5.04003081409745e-06,
      "loss": 0.0,
      "step": 54900
    },
    {
      "epoch": 2.254283137962128,
      "grad_norm": 9.481222473795015e-10,
      "learning_rate": 5.012518227088894e-06,
      "loss": 0.0,
      "step": 55000
    },
    {
      "epoch": 2.2583818345766047,
      "grad_norm": 1.1549972089852645e-09,
      "learning_rate": 4.985005640080337e-06,
      "loss": 0.0,
      "step": 55100
    },
    {
      "epoch": 2.2624805311910814,
      "grad_norm": 9.950900103916638e-10,
      "learning_rate": 4.957493053071781e-06,
      "loss": 0.0,
      "step": 55200
    },
    {
      "epoch": 2.2665792278055577,
      "grad_norm": 3.085173894135096e-09,
      "learning_rate": 4.9299804660632245e-06,
      "loss": 0.0,
      "step": 55300
    },
    {
      "epoch": 2.2706779244200344,
      "grad_norm": 7.613496499914163e-10,
      "learning_rate": 4.9024678790546685e-06,
      "loss": 0.0,
      "step": 55400
    },
    {
      "epoch": 2.274776621034511,
      "grad_norm": 1.8935717438495203e-09,
      "learning_rate": 4.8749552920461116e-06,
      "loss": 0.0,
      "step": 55500
    },
    {
      "epoch": 2.2788753176489878,
      "grad_norm": 2.4780715257577413e-09,
      "learning_rate": 4.847442705037555e-06,
      "loss": 0.0,
      "step": 55600
    },
    {
      "epoch": 2.282974014263464,
      "grad_norm": 1.4444735407792564e-09,
      "learning_rate": 4.819930118028999e-06,
      "loss": 0.0,
      "step": 55700
    },
    {
      "epoch": 2.2870727108779407,
      "grad_norm": 3.2439171349096796e-09,
      "learning_rate": 4.7924175310204425e-06,
      "loss": 0.0,
      "step": 55800
    },
    {
      "epoch": 2.2911714074924174,
      "grad_norm": 8.853043298451269e-10,
      "learning_rate": 4.7649049440118865e-06,
      "loss": 0.0,
      "step": 55900
    },
    {
      "epoch": 2.295270104106894,
      "grad_norm": 1.2856198328137225e-09,
      "learning_rate": 4.7373923570033295e-06,
      "loss": 0.0,
      "step": 56000
    },
    {
      "epoch": 2.2993688007213704,
      "grad_norm": 1.5945176290443897e-09,
      "learning_rate": 4.709879769994773e-06,
      "loss": 0.0,
      "step": 56100
    },
    {
      "epoch": 2.303467497335847,
      "grad_norm": 8.978904286749412e-10,
      "learning_rate": 4.6826423088563025e-06,
      "loss": 0.0,
      "step": 56200
    },
    {
      "epoch": 2.307566193950324,
      "grad_norm": 5.701181748918316e-10,
      "learning_rate": 4.6551297218477456e-06,
      "loss": 0.0,
      "step": 56300
    },
    {
      "epoch": 2.3116648905648005,
      "grad_norm": 7.010926839079445e-10,
      "learning_rate": 4.627617134839189e-06,
      "loss": 0.0,
      "step": 56400
    },
    {
      "epoch": 2.315763587179277,
      "grad_norm": 4.286489829752327e-09,
      "learning_rate": 4.600104547830633e-06,
      "loss": 0.0,
      "step": 56500
    },
    {
      "epoch": 2.3198622837937535,
      "grad_norm": 1.9906210013687087e-09,
      "learning_rate": 4.5725919608220765e-06,
      "loss": 0.0,
      "step": 56600
    },
    {
      "epoch": 2.32396098040823,
      "grad_norm": 1.0667193794944296e-09,
      "learning_rate": 4.5450793738135204e-06,
      "loss": 0.0,
      "step": 56700
    },
    {
      "epoch": 2.328059677022707,
      "grad_norm": 1.2263778881305143e-09,
      "learning_rate": 4.5175667868049635e-06,
      "loss": 0.0,
      "step": 56800
    },
    {
      "epoch": 2.332158373637183,
      "grad_norm": 1.4274256221469273e-09,
      "learning_rate": 4.490054199796407e-06,
      "loss": 0.0,
      "step": 56900
    },
    {
      "epoch": 2.33625707025166,
      "grad_norm": 1.8293004888647602e-09,
      "learning_rate": 4.4625416127878506e-06,
      "loss": 0.0,
      "step": 57000
    },
    {
      "epoch": 2.3403557668661366,
      "grad_norm": 7.929765177827619e-10,
      "learning_rate": 4.4350290257792945e-06,
      "loss": 0.0,
      "step": 57100
    },
    {
      "epoch": 2.3444544634806133,
      "grad_norm": 1.5444903134209653e-09,
      "learning_rate": 4.4075164387707384e-06,
      "loss": 0.0,
      "step": 57200
    },
    {
      "epoch": 2.34855316009509,
      "grad_norm": 6.750427994361985e-10,
      "learning_rate": 4.3800038517621815e-06,
      "loss": 0.0,
      "step": 57300
    },
    {
      "epoch": 2.3526518567095662,
      "grad_norm": 1.7891135239977984e-09,
      "learning_rate": 4.352491264753625e-06,
      "loss": 0.0,
      "step": 57400
    },
    {
      "epoch": 2.356750553324043,
      "grad_norm": 4.748190174375111e-10,
      "learning_rate": 4.3249786777450685e-06,
      "loss": 0.0,
      "step": 57500
    },
    {
      "epoch": 2.3608492499385196,
      "grad_norm": 1.351184275577566e-09,
      "learning_rate": 4.2974660907365125e-06,
      "loss": 0.0,
      "step": 57600
    },
    {
      "epoch": 2.3649479465529963,
      "grad_norm": 1.19702425749324e-09,
      "learning_rate": 4.269953503727956e-06,
      "loss": 0.0,
      "step": 57700
    },
    {
      "epoch": 2.3690466431674726,
      "grad_norm": 1.098351964934352e-09,
      "learning_rate": 4.2424409167193995e-06,
      "loss": 0.0,
      "step": 57800
    },
    {
      "epoch": 2.3731453397819493,
      "grad_norm": 6.256582474328809e-10,
      "learning_rate": 4.214928329710843e-06,
      "loss": 0.0,
      "step": 57900
    },
    {
      "epoch": 2.377244036396426,
      "grad_norm": 1.2208836164262493e-09,
      "learning_rate": 4.1874157427022865e-06,
      "loss": 0.0,
      "step": 58000
    },
    {
      "epoch": 2.3813427330109027,
      "grad_norm": 1.0130588590229195e-09,
      "learning_rate": 4.1599031556937304e-06,
      "loss": 0.0,
      "step": 58100
    },
    {
      "epoch": 2.385441429625379,
      "grad_norm": 3.6526386359980734e-09,
      "learning_rate": 4.1326656945552594e-06,
      "loss": 0.0,
      "step": 58200
    },
    {
      "epoch": 2.3895401262398557,
      "grad_norm": 2.8202460367054982e-09,
      "learning_rate": 4.1051531075467025e-06,
      "loss": 0.0,
      "step": 58300
    },
    {
      "epoch": 2.3936388228543324,
      "grad_norm": 1.587573850159174e-09,
      "learning_rate": 4.0776405205381465e-06,
      "loss": 0.0,
      "step": 58400
    },
    {
      "epoch": 2.397737519468809,
      "grad_norm": 8.920346683538583e-10,
      "learning_rate": 4.05012793352959e-06,
      "loss": 0.0,
      "step": 58500
    },
    {
      "epoch": 2.4018362160832853,
      "grad_norm": 6.374819561116851e-10,
      "learning_rate": 4.0226153465210335e-06,
      "loss": 0.0,
      "step": 58600
    },
    {
      "epoch": 2.405934912697762,
      "grad_norm": 1.684835937432183e-09,
      "learning_rate": 3.995102759512477e-06,
      "loss": 0.0,
      "step": 58700
    },
    {
      "epoch": 2.4100336093122388,
      "grad_norm": 9.884766338785766e-10,
      "learning_rate": 3.9675901725039205e-06,
      "loss": 0.0,
      "step": 58800
    },
    {
      "epoch": 2.4141323059267155,
      "grad_norm": 5.798916902222118e-10,
      "learning_rate": 3.9400775854953644e-06,
      "loss": 0.0,
      "step": 58900
    },
    {
      "epoch": 2.4182310025411917,
      "grad_norm": 1.1879481842669293e-09,
      "learning_rate": 3.912564998486808e-06,
      "loss": 0.0,
      "step": 59000
    },
    {
      "epoch": 2.4223296991556684,
      "grad_norm": 8.017642105784262e-10,
      "learning_rate": 3.8850524114782515e-06,
      "loss": 0.0,
      "step": 59100
    },
    {
      "epoch": 2.426428395770145,
      "grad_norm": 3.704256013037366e-09,
      "learning_rate": 3.857539824469695e-06,
      "loss": 0.0,
      "step": 59200
    },
    {
      "epoch": 2.430527092384622,
      "grad_norm": 2.8106903471325495e-09,
      "learning_rate": 3.8300272374611385e-06,
      "loss": 0.0,
      "step": 59300
    },
    {
      "epoch": 2.434625788999098,
      "grad_norm": 1.3076415505963723e-09,
      "learning_rate": 3.8025146504525824e-06,
      "loss": 0.0,
      "step": 59400
    },
    {
      "epoch": 2.438724485613575,
      "grad_norm": 1.2653216252545008e-09,
      "learning_rate": 3.775002063444026e-06,
      "loss": 0.0,
      "step": 59500
    },
    {
      "epoch": 2.4428231822280515,
      "grad_norm": 1.3986859448422706e-09,
      "learning_rate": 3.74748947643547e-06,
      "loss": 0.0,
      "step": 59600
    },
    {
      "epoch": 2.446921878842528,
      "grad_norm": 1.5640092554392027e-09,
      "learning_rate": 3.7199768894269134e-06,
      "loss": 0.0,
      "step": 59700
    },
    {
      "epoch": 2.4510205754570045,
      "grad_norm": 2.541503008046675e-09,
      "learning_rate": 3.6924643024183565e-06,
      "loss": 0.0,
      "step": 59800
    },
    {
      "epoch": 2.455119272071481,
      "grad_norm": 1.1493564988640514e-09,
      "learning_rate": 3.6649517154098004e-06,
      "loss": 0.0,
      "step": 59900
    },
    {
      "epoch": 2.459217968685958,
      "grad_norm": 1.1251514164811738e-09,
      "learning_rate": 3.637439128401244e-06,
      "loss": 0.0,
      "step": 60000
    },
    {
      "epoch": 2.4633166653004346,
      "grad_norm": 3.0007782925167703e-09,
      "learning_rate": 3.6099265413926874e-06,
      "loss": 0.0,
      "step": 60100
    },
    {
      "epoch": 2.4674153619149113,
      "grad_norm": 1.247120184899586e-09,
      "learning_rate": 3.5826890802542164e-06,
      "loss": 0.0,
      "step": 60200
    },
    {
      "epoch": 2.4715140585293875,
      "grad_norm": 6.635728633241911e-10,
      "learning_rate": 3.55517649324566e-06,
      "loss": 0.0,
      "step": 60300
    },
    {
      "epoch": 2.4756127551438643,
      "grad_norm": 1.4552317129101766e-09,
      "learning_rate": 3.527663906237104e-06,
      "loss": 0.0,
      "step": 60400
    },
    {
      "epoch": 2.479711451758341,
      "grad_norm": 5.408891667890714e-10,
      "learning_rate": 3.5001513192285474e-06,
      "loss": 0.0,
      "step": 60500
    },
    {
      "epoch": 2.483810148372817,
      "grad_norm": 8.284827268667527e-10,
      "learning_rate": 3.4726387322199913e-06,
      "loss": 0.0,
      "step": 60600
    },
    {
      "epoch": 2.487908844987294,
      "grad_norm": 6.642540961721011e-10,
      "learning_rate": 3.4451261452114344e-06,
      "loss": 0.0,
      "step": 60700
    },
    {
      "epoch": 2.4920075416017706,
      "grad_norm": 1.4794394598283134e-09,
      "learning_rate": 3.417613558202878e-06,
      "loss": 0.0,
      "step": 60800
    },
    {
      "epoch": 2.4961062382162473,
      "grad_norm": 2.593142811591065e-09,
      "learning_rate": 3.390100971194322e-06,
      "loss": 0.0,
      "step": 60900
    },
    {
      "epoch": 2.500204934830724,
      "grad_norm": 4.4476336502619063e-10,
      "learning_rate": 3.3625883841857653e-06,
      "loss": 0.0,
      "step": 61000
    },
    {
      "epoch": 2.5043036314452003,
      "grad_norm": 9.43492506344512e-10,
      "learning_rate": 3.3350757971772093e-06,
      "loss": 0.0,
      "step": 61100
    },
    {
      "epoch": 2.508402328059677,
      "grad_norm": 1.2124130588375692e-09,
      "learning_rate": 3.3075632101686524e-06,
      "loss": 0.0,
      "step": 61200
    },
    {
      "epoch": 2.5125010246741537,
      "grad_norm": 2.1816943807095868e-09,
      "learning_rate": 3.280050623160096e-06,
      "loss": 0.0,
      "step": 61300
    },
    {
      "epoch": 2.51659972128863,
      "grad_norm": 6.20890117097872e-10,
      "learning_rate": 3.25253803615154e-06,
      "loss": 0.0,
      "step": 61400
    },
    {
      "epoch": 2.5206984179031067,
      "grad_norm": 1.3004977095221193e-09,
      "learning_rate": 3.2250254491429833e-06,
      "loss": 0.0,
      "step": 61500
    },
    {
      "epoch": 2.5247971145175834,
      "grad_norm": 1.2849067365650058e-09,
      "learning_rate": 3.197512862134427e-06,
      "loss": 0.0,
      "step": 61600
    },
    {
      "epoch": 2.52889581113206,
      "grad_norm": 3.364621914414556e-10,
      "learning_rate": 3.1700002751258703e-06,
      "loss": 0.0,
      "step": 61700
    },
    {
      "epoch": 2.532994507746537,
      "grad_norm": 6.658082973842738e-10,
      "learning_rate": 3.142487688117314e-06,
      "loss": 0.0,
      "step": 61800
    },
    {
      "epoch": 2.537093204361013,
      "grad_norm": 2.2393711329726784e-09,
      "learning_rate": 3.1149751011087574e-06,
      "loss": 0.0,
      "step": 61900
    },
    {
      "epoch": 2.5411919009754897,
      "grad_norm": 7.975861637810056e-10,
      "learning_rate": 3.0874625141002013e-06,
      "loss": 0.0,
      "step": 62000
    },
    {
      "epoch": 2.5452905975899665,
      "grad_norm": 1.0349966439449076e-09,
      "learning_rate": 3.0599499270916444e-06,
      "loss": 0.0,
      "step": 62100
    },
    {
      "epoch": 2.5493892942044427,
      "grad_norm": 1.0381716597507307e-09,
      "learning_rate": 3.032712465953174e-06,
      "loss": 0.0,
      "step": 62200
    },
    {
      "epoch": 2.5534879908189194,
      "grad_norm": 2.064287185632452e-09,
      "learning_rate": 3.0051998789446173e-06,
      "loss": 0.0,
      "step": 62300
    },
    {
      "epoch": 2.557586687433396,
      "grad_norm": 9.525205069138565e-10,
      "learning_rate": 2.9776872919360612e-06,
      "loss": 0.0,
      "step": 62400
    },
    {
      "epoch": 2.561685384047873,
      "grad_norm": 1.0518476090126683e-09,
      "learning_rate": 2.9501747049275048e-06,
      "loss": 0.0,
      "step": 62500
    },
    {
      "epoch": 2.5657840806623495,
      "grad_norm": 1.182705378077742e-09,
      "learning_rate": 2.922662117918948e-06,
      "loss": 0.0,
      "step": 62600
    },
    {
      "epoch": 2.569882777276826,
      "grad_norm": 1.0547589468501428e-09,
      "learning_rate": 2.8951495309103918e-06,
      "loss": 0.0,
      "step": 62700
    },
    {
      "epoch": 2.5739814738913025,
      "grad_norm": 9.642834308820625e-10,
      "learning_rate": 2.8676369439018353e-06,
      "loss": 0.0,
      "step": 62800
    },
    {
      "epoch": 2.578080170505779,
      "grad_norm": 1.201425403607459e-09,
      "learning_rate": 2.8401243568932792e-06,
      "loss": 0.0,
      "step": 62900
    },
    {
      "epoch": 2.582178867120256,
      "grad_norm": 7.047440964136342e-10,
      "learning_rate": 2.8126117698847227e-06,
      "loss": 0.0,
      "step": 63000
    },
    {
      "epoch": 2.5862775637347326,
      "grad_norm": 8.44387837428684e-10,
      "learning_rate": 2.785099182876166e-06,
      "loss": 0.0,
      "step": 63100
    },
    {
      "epoch": 2.590376260349209,
      "grad_norm": 1.2632511703358773e-09,
      "learning_rate": 2.7575865958676098e-06,
      "loss": 0.0,
      "step": 63200
    },
    {
      "epoch": 2.5944749569636856,
      "grad_norm": 1.6434218430561032e-09,
      "learning_rate": 2.7300740088590533e-06,
      "loss": 0.0,
      "step": 63300
    },
    {
      "epoch": 2.5985736535781623,
      "grad_norm": 8.212478475044804e-10,
      "learning_rate": 2.7025614218504968e-06,
      "loss": 0.0,
      "step": 63400
    },
    {
      "epoch": 2.6026723501926385,
      "grad_norm": 2.019957534571404e-09,
      "learning_rate": 2.6750488348419407e-06,
      "loss": 0.0,
      "step": 63500
    },
    {
      "epoch": 2.6067710468071152,
      "grad_norm": 7.985264671717118e-10,
      "learning_rate": 2.647536247833384e-06,
      "loss": 0.0,
      "step": 63600
    },
    {
      "epoch": 2.610869743421592,
      "grad_norm": 4.6355677629783543e-10,
      "learning_rate": 2.6200236608248273e-06,
      "loss": 0.0,
      "step": 63700
    },
    {
      "epoch": 2.6149684400360687,
      "grad_norm": 4.434100586703238e-10,
      "learning_rate": 2.5925110738162712e-06,
      "loss": 0.0,
      "step": 63800
    },
    {
      "epoch": 2.6190671366505454,
      "grad_norm": 1.2923784264984306e-09,
      "learning_rate": 2.5649984868077148e-06,
      "loss": 0.0,
      "step": 63900
    },
    {
      "epoch": 2.6231658332650216,
      "grad_norm": 6.277044217739558e-09,
      "learning_rate": 2.537485899799158e-06,
      "loss": 0.0,
      "step": 64000
    },
    {
      "epoch": 2.6272645298794983,
      "grad_norm": 1.233631086172693e-09,
      "learning_rate": 2.5099733127906018e-06,
      "loss": 0.0,
      "step": 64100
    },
    {
      "epoch": 2.631363226493975,
      "grad_norm": 1.75076031450061e-09,
      "learning_rate": 2.482735851652131e-06,
      "loss": 0.0,
      "step": 64200
    },
    {
      "epoch": 2.6354619231084513,
      "grad_norm": 3.3823954748157803e-10,
      "learning_rate": 2.4552232646435747e-06,
      "loss": 0.0,
      "step": 64300
    },
    {
      "epoch": 2.639560619722928,
      "grad_norm": 2.1209829448309847e-09,
      "learning_rate": 2.427710677635018e-06,
      "loss": 0.0,
      "step": 64400
    },
    {
      "epoch": 2.6436593163374047,
      "grad_norm": 1.406412208915242e-09,
      "learning_rate": 2.4001980906264617e-06,
      "loss": 0.0,
      "step": 64500
    },
    {
      "epoch": 2.6477580129518814,
      "grad_norm": 1.3588004055264946e-09,
      "learning_rate": 2.3726855036179052e-06,
      "loss": 0.0,
      "step": 64600
    },
    {
      "epoch": 2.651856709566358,
      "grad_norm": 6.695967114112023e-10,
      "learning_rate": 2.345172916609349e-06,
      "loss": 0.0,
      "step": 64700
    },
    {
      "epoch": 2.6559554061808344,
      "grad_norm": 6.261625107306656e-10,
      "learning_rate": 2.3176603296007927e-06,
      "loss": 0.0,
      "step": 64800
    },
    {
      "epoch": 2.660054102795311,
      "grad_norm": 9.499746544960885e-10,
      "learning_rate": 2.290147742592236e-06,
      "loss": 0.0,
      "step": 64900
    },
    {
      "epoch": 2.6641527994097878,
      "grad_norm": 3.253005642633866e-09,
      "learning_rate": 2.2626351555836797e-06,
      "loss": 0.0,
      "step": 65000
    },
    {
      "epoch": 2.668251496024264,
      "grad_norm": 1.2889040945651686e-09,
      "learning_rate": 2.2351225685751232e-06,
      "loss": 0.0,
      "step": 65100
    },
    {
      "epoch": 2.6723501926387407,
      "grad_norm": 2.04453720620279e-09,
      "learning_rate": 2.2076099815665667e-06,
      "loss": 0.0,
      "step": 65200
    },
    {
      "epoch": 2.6764488892532174,
      "grad_norm": 1.3139845878029632e-09,
      "learning_rate": 2.1800973945580102e-06,
      "loss": 0.0,
      "step": 65300
    },
    {
      "epoch": 2.680547585867694,
      "grad_norm": 5.628598698237397e-10,
      "learning_rate": 2.152584807549454e-06,
      "loss": 0.0,
      "step": 65400
    },
    {
      "epoch": 2.684646282482171,
      "grad_norm": 5.1842397041923505e-09,
      "learning_rate": 2.1250722205408977e-06,
      "loss": 0.0,
      "step": 65500
    },
    {
      "epoch": 2.688744979096647,
      "grad_norm": 2.827257095106006e-09,
      "learning_rate": 2.097559633532341e-06,
      "loss": 0.0,
      "step": 65600
    },
    {
      "epoch": 2.692843675711124,
      "grad_norm": 2.05958383681093e-09,
      "learning_rate": 2.0700470465237847e-06,
      "loss": 0.0,
      "step": 65700
    },
    {
      "epoch": 2.6969423723256005,
      "grad_norm": 2.003115673332445e-09,
      "learning_rate": 2.0425344595152282e-06,
      "loss": 0.0,
      "step": 65800
    },
    {
      "epoch": 2.701041068940077,
      "grad_norm": 8.35365943085975e-10,
      "learning_rate": 2.015021872506672e-06,
      "loss": 0.0,
      "step": 65900
    },
    {
      "epoch": 2.7051397655545535,
      "grad_norm": 2.1556727514138174e-09,
      "learning_rate": 1.9875092854981157e-06,
      "loss": 0.0,
      "step": 66000
    },
    {
      "epoch": 2.70923846216903,
      "grad_norm": 4.677782605710945e-10,
      "learning_rate": 1.959996698489559e-06,
      "loss": 0.0,
      "step": 66100
    },
    {
      "epoch": 2.713337158783507,
      "grad_norm": 1.1028379320876525e-09,
      "learning_rate": 1.9327592373510886e-06,
      "loss": 0.0,
      "step": 66200
    },
    {
      "epoch": 2.7174358553979836,
      "grad_norm": 1.6979398997918338e-09,
      "learning_rate": 1.9052466503425319e-06,
      "loss": 0.0,
      "step": 66300
    },
    {
      "epoch": 2.72153455201246,
      "grad_norm": 6.741298630430492e-10,
      "learning_rate": 1.8777340633339756e-06,
      "loss": 0.0,
      "step": 66400
    },
    {
      "epoch": 2.7256332486269366,
      "grad_norm": 1.0022490615213542e-09,
      "learning_rate": 1.850221476325419e-06,
      "loss": 0.0,
      "step": 66500
    },
    {
      "epoch": 2.7297319452414133,
      "grad_norm": 4.2373429764985815e-10,
      "learning_rate": 1.8227088893168626e-06,
      "loss": 0.0,
      "step": 66600
    },
    {
      "epoch": 2.73383064185589,
      "grad_norm": 1.0155243312937046e-09,
      "learning_rate": 1.7951963023083063e-06,
      "loss": 0.0,
      "step": 66700
    },
    {
      "epoch": 2.7379293384703667,
      "grad_norm": 1.1211072070693717e-09,
      "learning_rate": 1.7676837152997496e-06,
      "loss": 0.0,
      "step": 66800
    },
    {
      "epoch": 2.742028035084843,
      "grad_norm": 2.60204280344567e-09,
      "learning_rate": 1.7401711282911934e-06,
      "loss": 0.0,
      "step": 66900
    },
    {
      "epoch": 2.7461267316993196,
      "grad_norm": 3.156390260272701e-09,
      "learning_rate": 1.7126585412826369e-06,
      "loss": 0.0,
      "step": 67000
    },
    {
      "epoch": 2.7502254283137963,
      "grad_norm": 1.5447594314821345e-09,
      "learning_rate": 1.6851459542740806e-06,
      "loss": 0.0,
      "step": 67100
    },
    {
      "epoch": 2.7543241249282726,
      "grad_norm": 6.591026613378403e-10,
      "learning_rate": 1.657633367265524e-06,
      "loss": 0.0,
      "step": 67200
    },
    {
      "epoch": 2.7584228215427493,
      "grad_norm": 9.173535264750399e-10,
      "learning_rate": 1.6301207802569676e-06,
      "loss": 0.0,
      "step": 67300
    },
    {
      "epoch": 2.762521518157226,
      "grad_norm": 1.1631428042946368e-09,
      "learning_rate": 1.6026081932484113e-06,
      "loss": 0.0,
      "step": 67400
    },
    {
      "epoch": 2.7666202147717027,
      "grad_norm": 3.894500277823454e-09,
      "learning_rate": 1.5750956062398549e-06,
      "loss": 0.0,
      "step": 67500
    },
    {
      "epoch": 2.7707189113861794,
      "grad_norm": 4.887921178919896e-10,
      "learning_rate": 1.5475830192312986e-06,
      "loss": 0.0,
      "step": 67600
    },
    {
      "epoch": 2.7748176080006557,
      "grad_norm": 1.078333089488126e-09,
      "learning_rate": 1.5200704322227419e-06,
      "loss": 0.0,
      "step": 67700
    },
    {
      "epoch": 2.7789163046151324,
      "grad_norm": 1.5818892862284883e-09,
      "learning_rate": 1.4925578452141856e-06,
      "loss": 0.0,
      "step": 67800
    },
    {
      "epoch": 2.783015001229609,
      "grad_norm": 1.3047088742723645e-08,
      "learning_rate": 1.4650452582056293e-06,
      "loss": 0.0,
      "step": 67900
    },
    {
      "epoch": 2.7871136978440854,
      "grad_norm": 5.653605361644054e-10,
      "learning_rate": 1.4375326711970728e-06,
      "loss": 0.0,
      "step": 68000
    },
    {
      "epoch": 2.791212394458562,
      "grad_norm": 9.306233006434184e-10,
      "learning_rate": 1.4100200841885164e-06,
      "loss": 0.0,
      "step": 68100
    },
    {
      "epoch": 2.7953110910730388,
      "grad_norm": 1.8164710846590992e-09,
      "learning_rate": 1.3827826230500455e-06,
      "loss": 0.0,
      "step": 68200
    },
    {
      "epoch": 2.7994097876875155,
      "grad_norm": 6.430987964378687e-10,
      "learning_rate": 1.355270036041489e-06,
      "loss": 0.0,
      "step": 68300
    },
    {
      "epoch": 2.803508484301992,
      "grad_norm": 1.769465907131007e-09,
      "learning_rate": 1.3277574490329326e-06,
      "loss": 0.0,
      "step": 68400
    },
    {
      "epoch": 2.8076071809164684,
      "grad_norm": 4.928663588366078e-10,
      "learning_rate": 1.3002448620243763e-06,
      "loss": 0.0,
      "step": 68500
    },
    {
      "epoch": 2.811705877530945,
      "grad_norm": 1.3881925609027235e-09,
      "learning_rate": 1.27273227501582e-06,
      "loss": 0.0,
      "step": 68600
    },
    {
      "epoch": 2.815804574145422,
      "grad_norm": 1.2514588254575187e-09,
      "learning_rate": 1.2452196880072633e-06,
      "loss": 0.0,
      "step": 68700
    },
    {
      "epoch": 2.819903270759898,
      "grad_norm": 4.2839554126317125e-09,
      "learning_rate": 1.217707100998707e-06,
      "loss": 0.0,
      "step": 68800
    },
    {
      "epoch": 2.824001967374375,
      "grad_norm": 9.700743541785073e-10,
      "learning_rate": 1.1901945139901506e-06,
      "loss": 0.0,
      "step": 68900
    },
    {
      "epoch": 2.8281006639888515,
      "grad_norm": 1.3518692831837598e-09,
      "learning_rate": 1.1626819269815943e-06,
      "loss": 0.0,
      "step": 69000
    },
    {
      "epoch": 2.832199360603328,
      "grad_norm": 3.425760508601883e-10,
      "learning_rate": 1.1351693399730378e-06,
      "loss": 0.0,
      "step": 69100
    },
    {
      "epoch": 2.836298057217805,
      "grad_norm": 2.0617469953521095e-09,
      "learning_rate": 1.1076567529644813e-06,
      "loss": 0.0,
      "step": 69200
    },
    {
      "epoch": 2.840396753832281,
      "grad_norm": 1.3469769744034465e-09,
      "learning_rate": 1.0801441659559248e-06,
      "loss": 0.0,
      "step": 69300
    },
    {
      "epoch": 2.844495450446758,
      "grad_norm": 1.1008324252159696e-09,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 0.0,
      "step": 69400
    },
    {
      "epoch": 2.8485941470612346,
      "grad_norm": 1.0028254893157396e-09,
      "learning_rate": 1.0251189919388123e-06,
      "loss": 0.0,
      "step": 69500
    },
    {
      "epoch": 2.852692843675711,
      "grad_norm": 8.05175148776982e-10,
      "learning_rate": 9.976064049302558e-07,
      "loss": 0.0,
      "step": 69600
    },
    {
      "epoch": 2.8567915402901876,
      "grad_norm": 1.283132156082445e-09,
      "learning_rate": 9.700938179216993e-07,
      "loss": 0.0,
      "step": 69700
    },
    {
      "epoch": 2.8608902369046643,
      "grad_norm": 2.003225807456488e-09,
      "learning_rate": 9.425812309131428e-07,
      "loss": 0.0,
      "step": 69800
    },
    {
      "epoch": 2.864988933519141,
      "grad_norm": 4.583390111889685e-09,
      "learning_rate": 9.150686439045864e-07,
      "loss": 0.0,
      "step": 69900
    },
    {
      "epoch": 2.8690876301336177,
      "grad_norm": 8.642409565773335e-10,
      "learning_rate": 8.875560568960299e-07,
      "loss": 0.0,
      "step": 70000
    },
    {
      "epoch": 2.873186326748094,
      "grad_norm": 1.3712516677699682e-09,
      "learning_rate": 8.600434698874736e-07,
      "loss": 0.0,
      "step": 70100
    },
    {
      "epoch": 2.8772850233625706,
      "grad_norm": 5.232702604551775e-10,
      "learning_rate": 8.328060087490028e-07,
      "loss": 0.0,
      "step": 70200
    },
    {
      "epoch": 2.8813837199770473,
      "grad_norm": 1.4926649916091606e-09,
      "learning_rate": 8.052934217404463e-07,
      "loss": 0.0,
      "step": 70300
    },
    {
      "epoch": 2.885482416591524,
      "grad_norm": 1.7503797300477686e-09,
      "learning_rate": 7.7778083473189e-07,
      "loss": 0.0,
      "step": 70400
    },
    {
      "epoch": 2.8895811132060008,
      "grad_norm": 5.570517380704132e-10,
      "learning_rate": 7.502682477233335e-07,
      "loss": 0.0,
      "step": 70500
    },
    {
      "epoch": 2.893679809820477,
      "grad_norm": 6.307775413105787e-10,
      "learning_rate": 7.227556607147771e-07,
      "loss": 0.0,
      "step": 70600
    },
    {
      "epoch": 2.8977785064349537,
      "grad_norm": 9.418232860269882e-10,
      "learning_rate": 6.952430737062206e-07,
      "loss": 0.0,
      "step": 70700
    },
    {
      "epoch": 2.9018772030494304,
      "grad_norm": 7.349780228871339e-10,
      "learning_rate": 6.677304866976643e-07,
      "loss": 0.0,
      "step": 70800
    },
    {
      "epoch": 2.9059758996639067,
      "grad_norm": 1.8572856586018816e-09,
      "learning_rate": 6.402178996891078e-07,
      "loss": 0.0,
      "step": 70900
    },
    {
      "epoch": 2.9100745962783834,
      "grad_norm": 8.921185457033687e-10,
      "learning_rate": 6.127053126805515e-07,
      "loss": 0.0,
      "step": 71000
    },
    {
      "epoch": 2.91417329289286,
      "grad_norm": 9.933236455594852e-10,
      "learning_rate": 5.85192725671995e-07,
      "loss": 0.0,
      "step": 71100
    },
    {
      "epoch": 2.918271989507337,
      "grad_norm": 1.280158312688684e-09,
      "learning_rate": 5.576801386634386e-07,
      "loss": 0.0,
      "step": 71200
    },
    {
      "epoch": 2.9223706861218135,
      "grad_norm": 1.6244748879401527e-09,
      "learning_rate": 5.301675516548822e-07,
      "loss": 0.0,
      "step": 71300
    },
    {
      "epoch": 2.9264693827362898,
      "grad_norm": 4.591584890079048e-10,
      "learning_rate": 5.026549646463257e-07,
      "loss": 0.0,
      "step": 71400
    },
    {
      "epoch": 2.9305680793507665,
      "grad_norm": 1.7513986927397696e-09,
      "learning_rate": 4.751423776377693e-07,
      "loss": 0.0,
      "step": 71500
    },
    {
      "epoch": 2.934666775965243,
      "grad_norm": 8.176337384924182e-10,
      "learning_rate": 4.476297906292129e-07,
      "loss": 0.0,
      "step": 71600
    },
    {
      "epoch": 2.9387654725797194,
      "grad_norm": 1.9160302233700577e-09,
      "learning_rate": 4.2011720362065645e-07,
      "loss": 0.0,
      "step": 71700
    },
    {
      "epoch": 2.942864169194196,
      "grad_norm": 1.0771246117258215e-09,
      "learning_rate": 3.926046166121001e-07,
      "loss": 0.0,
      "step": 71800
    },
    {
      "epoch": 2.946962865808673,
      "grad_norm": 9.606824225016908e-10,
      "learning_rate": 3.6509202960354364e-07,
      "loss": 0.0,
      "step": 71900
    },
    {
      "epoch": 2.9510615624231495,
      "grad_norm": 2.042766178433908e-09,
      "learning_rate": 3.375794425949872e-07,
      "loss": 0.0,
      "step": 72000
    },
    {
      "epoch": 2.9551602590376262,
      "grad_norm": 7.063767348824967e-10,
      "learning_rate": 3.100668555864308e-07,
      "loss": 0.0,
      "step": 72100
    },
    {
      "epoch": 2.9592589556521025,
      "grad_norm": 4.720859259066401e-10,
      "learning_rate": 2.8282939444795996e-07,
      "loss": 0.0,
      "step": 72200
    },
    {
      "epoch": 2.963357652266579,
      "grad_norm": 4.48687709209139e-09,
      "learning_rate": 2.5531680743940353e-07,
      "loss": 0.0,
      "step": 72300
    },
    {
      "epoch": 2.967456348881056,
      "grad_norm": 6.689107046042864e-09,
      "learning_rate": 2.2780422043084712e-07,
      "loss": 0.0,
      "step": 72400
    },
    {
      "epoch": 2.971555045495532,
      "grad_norm": 8.089471870142972e-10,
      "learning_rate": 2.0029163342229073e-07,
      "loss": 0.0,
      "step": 72500
    },
    {
      "epoch": 2.975653742110009,
      "grad_norm": 8.948599083957731e-10,
      "learning_rate": 1.7277904641373427e-07,
      "loss": 0.0,
      "step": 72600
    },
    {
      "epoch": 2.9797524387244856,
      "grad_norm": 9.245693655124398e-10,
      "learning_rate": 1.452664594051779e-07,
      "loss": 0.0,
      "step": 72700
    },
    {
      "epoch": 2.9838511353389623,
      "grad_norm": 7.999918505419146e-10,
      "learning_rate": 1.1775387239662147e-07,
      "loss": 0.0,
      "step": 72800
    },
    {
      "epoch": 2.987949831953439,
      "grad_norm": 1.2500720458774595e-09,
      "learning_rate": 9.024128538806504e-08,
      "loss": 0.0,
      "step": 72900
    },
    {
      "epoch": 2.9920485285679153,
      "grad_norm": 2.328722326083721e-09,
      "learning_rate": 6.272869837950863e-08,
      "loss": 0.0,
      "step": 73000
    },
    {
      "epoch": 2.996147225182392,
      "grad_norm": 3.1074703921163405e-10,
      "learning_rate": 3.521611137095221e-08,
      "loss": 0.0,
      "step": 73100
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 1.0,
      "eval_f1": 1.0,
      "eval_loss": 0.0,
      "eval_precision": 1.0,
      "eval_recall": 1.0,
      "eval_runtime": 468.0141,
      "eval_samples_per_second": 104.262,
      "eval_steps_per_second": 13.034,
      "step": 73194
    }
  ],
  "logging_steps": 100,
  "max_steps": 73194,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.540650092969595e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
